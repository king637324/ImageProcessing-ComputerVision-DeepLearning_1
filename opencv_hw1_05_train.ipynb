{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"opencv_hw1_05_train.ipynb","provenance":[],"authorship_tag":"ABX9TyOpCoJ819o5PFYUWIFBrMen"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WaOtbqfLa9hv","executionInfo":{"status":"ok","timestamp":1635390564190,"user_tz":-480,"elapsed":2799471,"user":{"displayName":"邱宜靜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYSQb7ldadtujLNYX93PbE2EKEFM2fI4X2ycdfsg=s64","userId":"01336892841119909216"}},"outputId":"9b243687-e5dc-429d-fda3-092ad5fe3663"},"source":["from sys import int_info\n","from time import sleep\n","\n","import numpy as np\n","import glob\n","import matplotlib.pyplot as plt\n","\n","import os\n","import cv2\n","import pickle\n","import random\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torchsummary import summary\n","\n","import warnings\n","\n","numClasses = 10\n","batch_size = 256\n","learning_rate = 0.01\n","op = 'SGD'\n","epochs =80\n","\n","optimizers = {'SGD':torch.optim.SGD, 'Adam':torch.optim.Adam, 'RMSprop':torch.optim.RMSprop}\n","\n","\n","# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","transform = transforms.Compose([transforms.ToTensor()])\n","trainDataset = torchvision.datasets.CIFAR10(root = './', train = True, download = True, transform = transform)\n","trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n","testDataset = torchvision.datasets.CIFAR10(root = './', train = False, download = True, transform = transform)\n","testLoader = torch.utils.data.DataLoader(testDataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n","\n","\n","class VGG16(nn.Module):\n","    def __init__(self, numClasses=10):\n","        super(VGG16, self).__init__()\n","        self.vgg16 = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(256, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.AvgPool2d((1, 1)),\n","            nn.Flatten(),\n","            nn.Linear(512 * 1 * 1, 4096), nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096), nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, numClasses)\n","        )\n","        \n","    def forward(self, x):\n","        x = self.vgg16(x)\n","        return x\n","\n","\n","\n","model = VGG16(numClasses=numClasses)\n","\n","use_gpu = torch.cuda.is_available()\n","if use_gpu:\n","    model = model.cuda()\n","\n","optimizer = optimizers[op](model.parameters(), lr=learning_rate, momentum=0.9)\n","criterion = nn.CrossEntropyLoss()\n","summary(model, input_size=(3, 32, 32))\n","\n","from tqdm import tqdm\n","from IPython.display import clear_output\n","\n","loss_epochs = []\n","train_acc_epochs = []\n","test_acc_epochs = []\n","\n","for epoch in range(epochs):\n","    loss_batch = 0.0\n","    acc_batch = 0.0\n","    model.train()\n","    for i, data in tqdm(enumerate(trainLoader, 1)):\n","        inputs, labels = data\n","        if use_gpu:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","        \n","        inputs = Variable(inputs)\n","        labels = Variable(labels)\n","        \n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        _, predicted = torch.max(outputs.data, 1)\n","        \n","        \n","        acc_batch += (predicted == labels).sum().item()\n","        loss_batch += loss.item()\n","        \n","        #print('[%d, %5d] loss: %.3f' % (epoch, i * batch_size, loss))\n","        #clear_output(wait=True)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        #break\n","        \n","        \n","    loss_batch /= i\n","    acc_batch /= (i * batch_size)\n","\n","    \n","    print(\"[%2d, %5d] Train Loss: %.3f\" % (epoch + 1, i * batch_size, loss_batch))\n","    print(\"[%2d, %5d] Train Accuracy: %.3f\" % (epoch + 1, i * batch_size, acc_batch))\n","\n","    loss_epochs.append(loss_batch)\n","    train_acc_epochs.append(acc_batch)\n","\n","    model.eval()\n","    loss_batch = 0.0\n","    acc_batch = 0.0\n","\n","    for i, data in enumerate(testLoader, 1):\n","        inputs, labels = data\n","        if use_gpu:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","        inputs = Variable(inputs, volatile=True)\n","        labels = Variable(labels, volatile=True)\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        _, predicted = torch.max(outputs.data, 1)\n","        num_correct = (predicted == labels).sum().item()\n","\n","        loss_batch += loss.item() \n","        acc_batch += num_correct\n","\n","    loss_batch /= i\n","    acc_batch /= (i * batch_size)\n","    test_acc_epochs.append(acc_batch)\n","\n","    print(\"[%2d, %5d] Test Loss: %.3f\" % (epoch + 1, i * batch_size, loss_batch))\n","    print(\"[%2d, %5d] Test Accuracy: %.3f\" % (epoch + 1, i * batch_size, acc_batch))\n","\n","print(loss_epochs)\n","print(train_acc_epochs)\n","print(test_acc_epochs)\n","torch.save(model, './drive/MyDrive/成大/vgg16_10280250.pkl',_use_new_zipfile_serialization=False)\n","\n"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","              ReLU-3           [-1, 64, 32, 32]               0\n","            Conv2d-4           [-1, 64, 32, 32]          36,928\n","       BatchNorm2d-5           [-1, 64, 32, 32]             128\n","              ReLU-6           [-1, 64, 32, 32]               0\n","         MaxPool2d-7           [-1, 64, 16, 16]               0\n","            Conv2d-8          [-1, 128, 16, 16]          73,856\n","       BatchNorm2d-9          [-1, 128, 16, 16]             256\n","             ReLU-10          [-1, 128, 16, 16]               0\n","           Conv2d-11          [-1, 128, 16, 16]         147,584\n","      BatchNorm2d-12          [-1, 128, 16, 16]             256\n","             ReLU-13          [-1, 128, 16, 16]               0\n","        MaxPool2d-14            [-1, 128, 8, 8]               0\n","           Conv2d-15            [-1, 256, 8, 8]         295,168\n","      BatchNorm2d-16            [-1, 256, 8, 8]             512\n","             ReLU-17            [-1, 256, 8, 8]               0\n","           Conv2d-18            [-1, 256, 8, 8]         590,080\n","      BatchNorm2d-19            [-1, 256, 8, 8]             512\n","             ReLU-20            [-1, 256, 8, 8]               0\n","           Conv2d-21            [-1, 256, 8, 8]         590,080\n","      BatchNorm2d-22            [-1, 256, 8, 8]             512\n","             ReLU-23            [-1, 256, 8, 8]               0\n","        MaxPool2d-24            [-1, 256, 4, 4]               0\n","           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n","      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n","             ReLU-27            [-1, 512, 4, 4]               0\n","           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n","      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n","             ReLU-30            [-1, 512, 4, 4]               0\n","           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n","      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n","             ReLU-33            [-1, 512, 4, 4]               0\n","        MaxPool2d-34            [-1, 512, 2, 2]               0\n","           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n","      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n","             ReLU-37            [-1, 512, 2, 2]               0\n","           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n","      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n","             ReLU-40            [-1, 512, 2, 2]               0\n","           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n","      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n","             ReLU-43            [-1, 512, 2, 2]               0\n","        MaxPool2d-44            [-1, 512, 1, 1]               0\n","        AvgPool2d-45            [-1, 512, 1, 1]               0\n","          Flatten-46                  [-1, 512]               0\n","           Linear-47                 [-1, 4096]       2,101,248\n","             ReLU-48                 [-1, 4096]               0\n","          Dropout-49                 [-1, 4096]               0\n","           Linear-50                 [-1, 4096]      16,781,312\n","             ReLU-51                 [-1, 4096]               0\n","          Dropout-52                 [-1, 4096]               0\n","           Linear-53                   [-1, 10]          40,970\n","================================================================\n","Total params: 33,646,666\n","Trainable params: 33,646,666\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 6.76\n","Params size (MB): 128.35\n","Estimated Total Size (MB): 135.13\n","----------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:09,  2.84it/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:148: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:149: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 1, 50176] Train Loss: 1.407\n","[ 1, 50176] Train Accuracy: 0.475\n","[ 1, 10240] Test Loss: 1.106\n","[ 1, 10240] Test Accuracy: 0.591\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 2, 50176] Train Loss: 0.833\n","[ 2, 50176] Train Accuracy: 0.706\n","[ 2, 10240] Test Loss: 0.919\n","[ 2, 10240] Test Accuracy: 0.671\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 3, 50176] Train Loss: 0.608\n","[ 3, 50176] Train Accuracy: 0.787\n","[ 3, 10240] Test Loss: 0.816\n","[ 3, 10240] Test Accuracy: 0.713\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 4, 50176] Train Loss: 0.467\n","[ 4, 50176] Train Accuracy: 0.837\n","[ 4, 10240] Test Loss: 0.661\n","[ 4, 10240] Test Accuracy: 0.762\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 5, 50176] Train Loss: 0.366\n","[ 5, 50176] Train Accuracy: 0.874\n","[ 5, 10240] Test Loss: 0.661\n","[ 5, 10240] Test Accuracy: 0.765\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 6, 50176] Train Loss: 0.281\n","[ 6, 50176] Train Accuracy: 0.902\n","[ 6, 10240] Test Loss: 0.667\n","[ 6, 10240] Test Accuracy: 0.780\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 7, 50176] Train Loss: 0.215\n","[ 7, 50176] Train Accuracy: 0.923\n","[ 7, 10240] Test Loss: 0.698\n","[ 7, 10240] Test Accuracy: 0.772\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 8, 50176] Train Loss: 0.180\n","[ 8, 50176] Train Accuracy: 0.935\n","[ 8, 10240] Test Loss: 0.647\n","[ 8, 10240] Test Accuracy: 0.794\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 9, 50176] Train Loss: 0.124\n","[ 9, 50176] Train Accuracy: 0.955\n","[ 9, 10240] Test Loss: 0.724\n","[ 9, 10240] Test Accuracy: 0.789\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[10, 50176] Train Loss: 0.110\n","[10, 50176] Train Accuracy: 0.960\n","[10, 10240] Test Loss: 0.966\n","[10, 10240] Test Accuracy: 0.755\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[11, 50176] Train Loss: 0.088\n","[11, 50176] Train Accuracy: 0.967\n","[11, 10240] Test Loss: 0.752\n","[11, 10240] Test Accuracy: 0.792\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[12, 50176] Train Loss: 0.071\n","[12, 50176] Train Accuracy: 0.973\n","[12, 10240] Test Loss: 0.874\n","[12, 10240] Test Accuracy: 0.784\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[13, 50176] Train Loss: 0.058\n","[13, 50176] Train Accuracy: 0.977\n","[13, 10240] Test Loss: 0.775\n","[13, 10240] Test Accuracy: 0.803\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[14, 50176] Train Loss: 0.049\n","[14, 50176] Train Accuracy: 0.981\n","[14, 10240] Test Loss: 0.791\n","[14, 10240] Test Accuracy: 0.809\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[15, 50176] Train Loss: 0.042\n","[15, 50176] Train Accuracy: 0.982\n","[15, 10240] Test Loss: 0.983\n","[15, 10240] Test Accuracy: 0.786\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[16, 50176] Train Loss: 0.042\n","[16, 50176] Train Accuracy: 0.982\n","[16, 10240] Test Loss: 0.882\n","[16, 10240] Test Accuracy: 0.796\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[17, 50176] Train Loss: 0.035\n","[17, 50176] Train Accuracy: 0.985\n","[17, 10240] Test Loss: 0.811\n","[17, 10240] Test Accuracy: 0.807\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[18, 50176] Train Loss: 0.029\n","[18, 50176] Train Accuracy: 0.987\n","[18, 10240] Test Loss: 0.886\n","[18, 10240] Test Accuracy: 0.806\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[19, 50176] Train Loss: 0.028\n","[19, 50176] Train Accuracy: 0.987\n","[19, 10240] Test Loss: 0.873\n","[19, 10240] Test Accuracy: 0.806\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[20, 50176] Train Loss: 0.028\n","[20, 50176] Train Accuracy: 0.987\n","[20, 10240] Test Loss: 0.776\n","[20, 10240] Test Accuracy: 0.811\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[21, 50176] Train Loss: 0.019\n","[21, 50176] Train Accuracy: 0.990\n","[21, 10240] Test Loss: 0.791\n","[21, 10240] Test Accuracy: 0.823\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[22, 50176] Train Loss: 0.015\n","[22, 50176] Train Accuracy: 0.992\n","[22, 10240] Test Loss: 0.836\n","[22, 10240] Test Accuracy: 0.818\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[23, 50176] Train Loss: 0.021\n","[23, 50176] Train Accuracy: 0.989\n","[23, 10240] Test Loss: 0.855\n","[23, 10240] Test Accuracy: 0.817\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[24, 50176] Train Loss: 0.017\n","[24, 50176] Train Accuracy: 0.991\n","[24, 10240] Test Loss: 0.913\n","[24, 10240] Test Accuracy: 0.812\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[25, 50176] Train Loss: 0.018\n","[25, 50176] Train Accuracy: 0.991\n","[25, 10240] Test Loss: 0.890\n","[25, 10240] Test Accuracy: 0.814\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[26, 50176] Train Loss: 0.017\n","[26, 50176] Train Accuracy: 0.991\n","[26, 10240] Test Loss: 0.899\n","[26, 10240] Test Accuracy: 0.818\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[27, 50176] Train Loss: 0.015\n","[27, 50176] Train Accuracy: 0.992\n","[27, 10240] Test Loss: 0.922\n","[27, 10240] Test Accuracy: 0.813\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[28, 50176] Train Loss: 0.015\n","[28, 50176] Train Accuracy: 0.992\n","[28, 10240] Test Loss: 0.953\n","[28, 10240] Test Accuracy: 0.812\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[29, 50176] Train Loss: 0.015\n","[29, 50176] Train Accuracy: 0.991\n","[29, 10240] Test Loss: 0.926\n","[29, 10240] Test Accuracy: 0.818\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[30, 50176] Train Loss: 0.009\n","[30, 50176] Train Accuracy: 0.994\n","[30, 10240] Test Loss: 0.857\n","[30, 10240] Test Accuracy: 0.820\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[31, 50176] Train Loss: 0.005\n","[31, 50176] Train Accuracy: 0.995\n","[31, 10240] Test Loss: 0.854\n","[31, 10240] Test Accuracy: 0.830\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[32, 50176] Train Loss: 0.007\n","[32, 50176] Train Accuracy: 0.994\n","[32, 10240] Test Loss: 1.019\n","[32, 10240] Test Accuracy: 0.805\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[33, 50176] Train Loss: 0.010\n","[33, 50176] Train Accuracy: 0.993\n","[33, 10240] Test Loss: 0.896\n","[33, 10240] Test Accuracy: 0.824\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[34, 50176] Train Loss: 0.018\n","[34, 50176] Train Accuracy: 0.991\n","[34, 10240] Test Loss: 0.923\n","[34, 10240] Test Accuracy: 0.819\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[35, 50176] Train Loss: 0.008\n","[35, 50176] Train Accuracy: 0.994\n","[35, 10240] Test Loss: 0.889\n","[35, 10240] Test Accuracy: 0.821\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[36, 50176] Train Loss: 0.006\n","[36, 50176] Train Accuracy: 0.994\n","[36, 10240] Test Loss: 0.960\n","[36, 10240] Test Accuracy: 0.822\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[37, 50176] Train Loss: 0.012\n","[37, 50176] Train Accuracy: 0.993\n","[37, 10240] Test Loss: 0.862\n","[37, 10240] Test Accuracy: 0.822\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[38, 50176] Train Loss: 0.007\n","[38, 50176] Train Accuracy: 0.995\n","[38, 10240] Test Loss: 0.882\n","[38, 10240] Test Accuracy: 0.825\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[39, 50176] Train Loss: 0.004\n","[39, 50176] Train Accuracy: 0.995\n","[39, 10240] Test Loss: 0.927\n","[39, 10240] Test Accuracy: 0.828\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[40, 50176] Train Loss: 0.004\n","[40, 50176] Train Accuracy: 0.995\n","[40, 10240] Test Loss: 0.894\n","[40, 10240] Test Accuracy: 0.832\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[41, 50176] Train Loss: 0.004\n","[41, 50176] Train Accuracy: 0.995\n","[41, 10240] Test Loss: 0.940\n","[41, 10240] Test Accuracy: 0.826\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[42, 50176] Train Loss: 0.010\n","[42, 50176] Train Accuracy: 0.993\n","[42, 10240] Test Loss: 0.942\n","[42, 10240] Test Accuracy: 0.821\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[43, 50176] Train Loss: 0.011\n","[43, 50176] Train Accuracy: 0.993\n","[43, 10240] Test Loss: 0.888\n","[43, 10240] Test Accuracy: 0.823\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[44, 50176] Train Loss: 0.006\n","[44, 50176] Train Accuracy: 0.994\n","[44, 10240] Test Loss: 1.016\n","[44, 10240] Test Accuracy: 0.817\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[45, 50176] Train Loss: 0.007\n","[45, 50176] Train Accuracy: 0.994\n","[45, 10240] Test Loss: 0.899\n","[45, 10240] Test Accuracy: 0.829\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[46, 50176] Train Loss: 0.005\n","[46, 50176] Train Accuracy: 0.995\n","[46, 10240] Test Loss: 0.885\n","[46, 10240] Test Accuracy: 0.834\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[47, 50176] Train Loss: 0.002\n","[47, 50176] Train Accuracy: 0.996\n","[47, 10240] Test Loss: 0.868\n","[47, 10240] Test Accuracy: 0.833\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[48, 50176] Train Loss: 0.002\n","[48, 50176] Train Accuracy: 0.996\n","[48, 10240] Test Loss: 0.884\n","[48, 10240] Test Accuracy: 0.833\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[49, 50176] Train Loss: 0.006\n","[49, 50176] Train Accuracy: 0.994\n","[49, 10240] Test Loss: 1.134\n","[49, 10240] Test Accuracy: 0.809\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[50, 50176] Train Loss: 0.011\n","[50, 50176] Train Accuracy: 0.993\n","[50, 10240] Test Loss: 0.885\n","[50, 10240] Test Accuracy: 0.829\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[51, 50176] Train Loss: 0.005\n","[51, 50176] Train Accuracy: 0.995\n","[51, 10240] Test Loss: 0.861\n","[51, 10240] Test Accuracy: 0.831\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[52, 50176] Train Loss: 0.005\n","[52, 50176] Train Accuracy: 0.995\n","[52, 10240] Test Loss: 0.881\n","[52, 10240] Test Accuracy: 0.828\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[53, 50176] Train Loss: 0.002\n","[53, 50176] Train Accuracy: 0.996\n","[53, 10240] Test Loss: 0.901\n","[53, 10240] Test Accuracy: 0.833\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[54, 50176] Train Loss: 0.001\n","[54, 50176] Train Accuracy: 0.996\n","[54, 10240] Test Loss: 0.921\n","[54, 10240] Test Accuracy: 0.833\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[55, 50176] Train Loss: 0.001\n","[55, 50176] Train Accuracy: 0.996\n","[55, 10240] Test Loss: 0.880\n","[55, 10240] Test Accuracy: 0.840\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[56, 50176] Train Loss: 0.000\n","[56, 50176] Train Accuracy: 0.996\n","[56, 10240] Test Loss: 0.873\n","[56, 10240] Test Accuracy: 0.840\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[57, 50176] Train Loss: 0.000\n","[57, 50176] Train Accuracy: 0.996\n","[57, 10240] Test Loss: 0.899\n","[57, 10240] Test Accuracy: 0.841\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[58, 50176] Train Loss: 0.000\n","[58, 50176] Train Accuracy: 0.996\n","[58, 10240] Test Loss: 0.857\n","[58, 10240] Test Accuracy: 0.842\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[59, 50176] Train Loss: 0.000\n","[59, 50176] Train Accuracy: 0.996\n","[59, 10240] Test Loss: 0.885\n","[59, 10240] Test Accuracy: 0.843\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[60, 50176] Train Loss: 0.000\n","[60, 50176] Train Accuracy: 0.996\n","[60, 10240] Test Loss: 0.915\n","[60, 10240] Test Accuracy: 0.844\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[61, 50176] Train Loss: 0.000\n","[61, 50176] Train Accuracy: 0.996\n","[61, 10240] Test Loss: 0.910\n","[61, 10240] Test Accuracy: 0.844\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:09,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[62, 50176] Train Loss: 0.000\n","[62, 50176] Train Accuracy: 0.996\n","[62, 10240] Test Loss: 0.873\n","[62, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:09,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[63, 50176] Train Loss: 0.000\n","[63, 50176] Train Accuracy: 0.996\n","[63, 10240] Test Loss: 0.867\n","[63, 10240] Test Accuracy: 0.846\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[64, 50176] Train Loss: 0.000\n","[64, 50176] Train Accuracy: 0.996\n","[64, 10240] Test Loss: 0.873\n","[64, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[65, 50176] Train Loss: 0.000\n","[65, 50176] Train Accuracy: 0.996\n","[65, 10240] Test Loss: 0.888\n","[65, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[66, 50176] Train Loss: 0.000\n","[66, 50176] Train Accuracy: 0.996\n","[66, 10240] Test Loss: 0.878\n","[66, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[67, 50176] Train Loss: 0.000\n","[67, 50176] Train Accuracy: 0.996\n","[67, 10240] Test Loss: 0.887\n","[67, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[68, 50176] Train Loss: 0.000\n","[68, 50176] Train Accuracy: 0.996\n","[68, 10240] Test Loss: 0.897\n","[68, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[69, 50176] Train Loss: 0.000\n","[69, 50176] Train Accuracy: 0.996\n","[69, 10240] Test Loss: 0.914\n","[69, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:09,  2.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[70, 50176] Train Loss: 0.000\n","[70, 50176] Train Accuracy: 0.996\n","[70, 10240] Test Loss: 0.899\n","[70, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[71, 50176] Train Loss: 0.000\n","[71, 50176] Train Accuracy: 0.996\n","[71, 10240] Test Loss: 0.892\n","[71, 10240] Test Accuracy: 0.844\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[72, 50176] Train Loss: 0.000\n","[72, 50176] Train Accuracy: 0.996\n","[72, 10240] Test Loss: 0.928\n","[72, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[73, 50176] Train Loss: 0.000\n","[73, 50176] Train Accuracy: 0.996\n","[73, 10240] Test Loss: 0.900\n","[73, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[74, 50176] Train Loss: 0.000\n","[74, 50176] Train Accuracy: 0.996\n","[74, 10240] Test Loss: 0.884\n","[74, 10240] Test Accuracy: 0.846\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[75, 50176] Train Loss: 0.000\n","[75, 50176] Train Accuracy: 0.996\n","[75, 10240] Test Loss: 0.887\n","[75, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[76, 50176] Train Loss: 0.000\n","[76, 50176] Train Accuracy: 0.996\n","[76, 10240] Test Loss: 0.922\n","[76, 10240] Test Accuracy: 0.846\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[77, 50176] Train Loss: 0.000\n","[77, 50176] Train Accuracy: 0.996\n","[77, 10240] Test Loss: 0.929\n","[77, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[78, 50176] Train Loss: 0.000\n","[78, 50176] Train Accuracy: 0.996\n","[78, 10240] Test Loss: 0.922\n","[78, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[79, 50176] Train Loss: 0.000\n","[79, 50176] Train Accuracy: 0.996\n","[79, 10240] Test Loss: 0.909\n","[79, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[80, 50176] Train Loss: 0.000\n","[80, 50176] Train Accuracy: 0.996\n","[80, 10240] Test Loss: 0.904\n","[80, 10240] Test Accuracy: 0.844\n","[1.40666156186133, 0.8332906006550302, 0.6077227543811409, 0.46742488687135736, 0.3662230696301071, 0.2807674648202195, 0.21493795042743488, 0.18018387254251508, 0.12424715353670168, 0.10963830125651189, 0.08758355987885473, 0.07112528568095698, 0.05765486833145272, 0.0486488381486234, 0.041610374904180666, 0.04163345575275622, 0.03453756588967327, 0.028865786232481882, 0.027978513557321335, 0.027612552217835068, 0.019376123229597638, 0.014959357600488072, 0.02117907021750639, 0.017067622090749232, 0.017571368521555775, 0.01727375387551491, 0.01456742866169091, 0.015270360937337297, 0.015184479813704419, 0.008995889034033136, 0.005365769404974975, 0.007481309945061946, 0.010428300180397596, 0.017583923103413734, 0.008311317235615096, 0.005993896966434217, 0.01166478907792652, 0.0069481559355840635, 0.003756215730687955, 0.004417144415574326, 0.0043402038374960265, 0.009909936653067624, 0.01066403331075277, 0.006201789843729859, 0.006965797948080818, 0.004855991107303582, 0.00183860988413564, 0.001685429612354376, 0.006449987368072545, 0.010651396576799832, 0.005359693206405702, 0.005371081198935993, 0.0021225553164742673, 0.001490768519200786, 0.000625242341579813, 0.0003177018182780056, 0.0001291844596102126, 9.67617713392744e-05, 5.848990404928725e-05, 0.00018433994697790362, 5.345083088184542e-05, 3.591698929753597e-05, 2.8578914740434383e-05, 2.762491753020761e-05, 2.2912988175467408e-05, 2.068913884228578e-05, 1.693329232747304e-05, 1.72367768785228e-05, 1.6899131100337992e-05, 1.6127760173332013e-05, 1.355213690050398e-05, 1.363351558856433e-05, 1.5986685262268278e-05, 1.3789292061536966e-05, 1.0765350600765989e-05, 1.1069157386716644e-05, 1.2775606604946563e-05, 1.1674208234562313e-05, 1.0292720055670599e-05, 9.776257506789024e-06]\n","[0.47544642857142855, 0.7059550382653061, 0.7869300063775511, 0.8374123086734694, 0.8739237882653061, 0.9015066964285714, 0.9233697385204082, 0.9354671556122449, 0.955436862244898, 0.9600406568877551, 0.9670360331632653, 0.9725366709183674, 0.977180325255102, 0.9805484693877551, 0.9820033482142857, 0.9822026466836735, 0.9847138073979592, 0.9872648278061225, 0.9865872130102041, 0.9869260204081632, 0.9903340242346939, 0.9918885522959183, 0.9892777423469388, 0.9909119897959183, 0.9907525510204082, 0.9905133928571429, 0.9916294642857143, 0.9916892538265306, 0.9912109375, 0.9936025191326531, 0.9946787308673469, 0.9942004145408163, 0.9934630102040817, 0.9908721301020408, 0.9939213966836735, 0.9944794323979592, 0.9927654655612245, 0.9945790816326531, 0.9953164859693877, 0.9950175382653061, 0.9952566964285714, 0.9934829400510204, 0.9931640625, 0.9943797831632653, 0.9942602040816326, 0.9947983099489796, 0.9958346619897959, 0.9960738201530612, 0.9944595025510204, 0.9930843431122449, 0.9949178890306123, 0.9949577487244898, 0.9957549426020408, 0.99609375, 0.9963129783163265, 0.9964126275510204, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964325573979592, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755]\n","[0.59091796875, 0.67099609375, 0.7130859375, 0.7615234375, 0.76513671875, 0.78037109375, 0.7720703125, 0.79375, 0.7890625, 0.7552734375, 0.7921875, 0.78408203125, 0.8033203125, 0.80859375, 0.78564453125, 0.79609375, 0.8072265625, 0.80556640625, 0.80595703125, 0.81064453125, 0.8232421875, 0.81796875, 0.81689453125, 0.8125, 0.814453125, 0.817578125, 0.81318359375, 0.8115234375, 0.818359375, 0.819921875, 0.82958984375, 0.805078125, 0.82412109375, 0.819140625, 0.82060546875, 0.8224609375, 0.822265625, 0.825, 0.8275390625, 0.831640625, 0.826171875, 0.82080078125, 0.82294921875, 0.8171875, 0.82880859375, 0.834375, 0.833203125, 0.83310546875, 0.8087890625, 0.82880859375, 0.83125, 0.82802734375, 0.8333984375, 0.83310546875, 0.8396484375, 0.83974609375, 0.8408203125, 0.84208984375, 0.8431640625, 0.84404296875, 0.84384765625, 0.84482421875, 0.84609375, 0.84453125, 0.84501953125, 0.84462890625, 0.84501953125, 0.844921875, 0.84482421875, 0.84541015625, 0.8443359375, 0.844921875, 0.8447265625, 0.8458984375, 0.8453125, 0.84599609375, 0.84482421875, 0.84462890625, 0.8451171875, 0.8443359375]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/serialization.py:405: UserWarning: Couldn't retrieve source code for container of type VGG16. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MwzdfoOSZzX8","executionInfo":{"status":"ok","timestamp":1635390564190,"user_tz":-480,"elapsed":2799471,"user":{"displayName":"邱宜靜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYSQb7ldadtujLNYX93PbE2EKEFM2fI4X2ycdfsg=s64","userId":"01336892841119909216"}},"outputId":"9b243687-e5dc-429d-fda3-092ad5fe3663"},"source":["from sys import int_info\n","from time import sleep\n","\n","import numpy as np\n","import glob\n","import matplotlib.pyplot as plt\n","\n","import os\n","import cv2\n","import pickle\n","import random\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","import torchvision.transforms as transforms\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torchsummary import summary\n","\n","import warnings\n","\n","numClasses = 10\n","batch_size = 256\n","learning_rate = 0.01\n","op = 'SGD'\n","epochs =80\n","\n","optimizers = {'SGD':torch.optim.SGD, 'Adam':torch.optim.Adam, 'RMSprop':torch.optim.RMSprop}\n","\n","\n","# transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","transform = transforms.Compose([transforms.ToTensor()])\n","trainDataset = torchvision.datasets.CIFAR10(root = './', train = True, download = True, transform = transform)\n","trainLoader = torch.utils.data.DataLoader(trainDataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n","testDataset = torchvision.datasets.CIFAR10(root = './', train = False, download = True, transform = transform)\n","testLoader = torch.utils.data.DataLoader(testDataset, batch_size = batch_size, shuffle = True, num_workers = 0)\n","\n","\n","class VGG16(nn.Module):\n","    def __init__(self, numClasses=10):\n","        super(VGG16, self).__init__()\n","        self.vgg16 = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(256, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.Conv2d(512, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.AvgPool2d((1, 1)),\n","            nn.Flatten(),\n","            nn.Linear(512 * 1 * 1, 4096), nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096), nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, numClasses)\n","        )\n","        \n","    def forward(self, x):\n","        x = self.vgg16(x)\n","        return x\n","\n","\n","\n","model = VGG16(numClasses=numClasses)\n","\n","use_gpu = torch.cuda.is_available()\n","if use_gpu:\n","    model = model.cuda()\n","\n","optimizer = optimizers[op](model.parameters(), lr=learning_rate, momentum=0.9)\n","criterion = nn.CrossEntropyLoss()\n","summary(model, input_size=(3, 32, 32))\n","\n","from tqdm import tqdm\n","from IPython.display import clear_output\n","\n","loss_epochs = []\n","train_acc_epochs = []\n","test_acc_epochs = []\n","\n","for epoch in range(epochs):\n","    loss_batch = 0.0\n","    acc_batch = 0.0\n","    model.train()\n","    for i, data in tqdm(enumerate(trainLoader, 1)):\n","        inputs, labels = data\n","        if use_gpu:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","        \n","        inputs = Variable(inputs)\n","        labels = Variable(labels)\n","        \n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        _, predicted = torch.max(outputs.data, 1)\n","        \n","        \n","        acc_batch += (predicted == labels).sum().item()\n","        loss_batch += loss.item()\n","        \n","        #print('[%d, %5d] loss: %.3f' % (epoch, i * batch_size, loss))\n","        #clear_output(wait=True)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        #break\n","        \n","        \n","    loss_batch /= i\n","    acc_batch /= (i * batch_size)\n","\n","    \n","    print(\"[%2d, %5d] Train Loss: %.3f\" % (epoch + 1, i * batch_size, loss_batch))\n","    print(\"[%2d, %5d] Train Accuracy: %.3f\" % (epoch + 1, i * batch_size, acc_batch))\n","\n","    loss_epochs.append(loss_batch)\n","    train_acc_epochs.append(acc_batch)\n","\n","    model.eval()\n","    loss_batch = 0.0\n","    acc_batch = 0.0\n","\n","    for i, data in enumerate(testLoader, 1):\n","        inputs, labels = data\n","        if use_gpu:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","        inputs = Variable(inputs, volatile=True)\n","        labels = Variable(labels, volatile=True)\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        _, predicted = torch.max(outputs.data, 1)\n","        num_correct = (predicted == labels).sum().item()\n","\n","        loss_batch += loss.item() \n","        acc_batch += num_correct\n","\n","    loss_batch /= i\n","    acc_batch /= (i * batch_size)\n","    test_acc_epochs.append(acc_batch)\n","\n","    print(\"[%2d, %5d] Test Loss: %.3f\" % (epoch + 1, i * batch_size, loss_batch))\n","    print(\"[%2d, %5d] Test Accuracy: %.3f\" % (epoch + 1, i * batch_size, acc_batch))\n","\n","print(loss_epochs)\n","print(train_acc_epochs)\n","print(test_acc_epochs)\n","torch.save(model, './drive/MyDrive/成大/vgg16_10280250.pkl',_use_new_zipfile_serialization=False)\n","\n"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 64, 32, 32]           1,792\n","       BatchNorm2d-2           [-1, 64, 32, 32]             128\n","              ReLU-3           [-1, 64, 32, 32]               0\n","            Conv2d-4           [-1, 64, 32, 32]          36,928\n","       BatchNorm2d-5           [-1, 64, 32, 32]             128\n","              ReLU-6           [-1, 64, 32, 32]               0\n","         MaxPool2d-7           [-1, 64, 16, 16]               0\n","            Conv2d-8          [-1, 128, 16, 16]          73,856\n","       BatchNorm2d-9          [-1, 128, 16, 16]             256\n","             ReLU-10          [-1, 128, 16, 16]               0\n","           Conv2d-11          [-1, 128, 16, 16]         147,584\n","      BatchNorm2d-12          [-1, 128, 16, 16]             256\n","             ReLU-13          [-1, 128, 16, 16]               0\n","        MaxPool2d-14            [-1, 128, 8, 8]               0\n","           Conv2d-15            [-1, 256, 8, 8]         295,168\n","      BatchNorm2d-16            [-1, 256, 8, 8]             512\n","             ReLU-17            [-1, 256, 8, 8]               0\n","           Conv2d-18            [-1, 256, 8, 8]         590,080\n","      BatchNorm2d-19            [-1, 256, 8, 8]             512\n","             ReLU-20            [-1, 256, 8, 8]               0\n","           Conv2d-21            [-1, 256, 8, 8]         590,080\n","      BatchNorm2d-22            [-1, 256, 8, 8]             512\n","             ReLU-23            [-1, 256, 8, 8]               0\n","        MaxPool2d-24            [-1, 256, 4, 4]               0\n","           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n","      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n","             ReLU-27            [-1, 512, 4, 4]               0\n","           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n","      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n","             ReLU-30            [-1, 512, 4, 4]               0\n","           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n","      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n","             ReLU-33            [-1, 512, 4, 4]               0\n","        MaxPool2d-34            [-1, 512, 2, 2]               0\n","           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n","      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n","             ReLU-37            [-1, 512, 2, 2]               0\n","           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n","      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n","             ReLU-40            [-1, 512, 2, 2]               0\n","           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n","      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n","             ReLU-43            [-1, 512, 2, 2]               0\n","        MaxPool2d-44            [-1, 512, 1, 1]               0\n","        AvgPool2d-45            [-1, 512, 1, 1]               0\n","          Flatten-46                  [-1, 512]               0\n","           Linear-47                 [-1, 4096]       2,101,248\n","             ReLU-48                 [-1, 4096]               0\n","          Dropout-49                 [-1, 4096]               0\n","           Linear-50                 [-1, 4096]      16,781,312\n","             ReLU-51                 [-1, 4096]               0\n","          Dropout-52                 [-1, 4096]               0\n","           Linear-53                   [-1, 10]          40,970\n","================================================================\n","Total params: 33,646,666\n","Trainable params: 33,646,666\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 6.76\n","Params size (MB): 128.35\n","Estimated Total Size (MB): 135.13\n","----------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:09,  2.84it/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:148: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:149: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 1, 50176] Train Loss: 1.407\n","[ 1, 50176] Train Accuracy: 0.475\n","[ 1, 10240] Test Loss: 1.106\n","[ 1, 10240] Test Accuracy: 0.591\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 2, 50176] Train Loss: 0.833\n","[ 2, 50176] Train Accuracy: 0.706\n","[ 2, 10240] Test Loss: 0.919\n","[ 2, 10240] Test Accuracy: 0.671\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 3, 50176] Train Loss: 0.608\n","[ 3, 50176] Train Accuracy: 0.787\n","[ 3, 10240] Test Loss: 0.816\n","[ 3, 10240] Test Accuracy: 0.713\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 4, 50176] Train Loss: 0.467\n","[ 4, 50176] Train Accuracy: 0.837\n","[ 4, 10240] Test Loss: 0.661\n","[ 4, 10240] Test Accuracy: 0.762\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 5, 50176] Train Loss: 0.366\n","[ 5, 50176] Train Accuracy: 0.874\n","[ 5, 10240] Test Loss: 0.661\n","[ 5, 10240] Test Accuracy: 0.765\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 6, 50176] Train Loss: 0.281\n","[ 6, 50176] Train Accuracy: 0.902\n","[ 6, 10240] Test Loss: 0.667\n","[ 6, 10240] Test Accuracy: 0.780\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 7, 50176] Train Loss: 0.215\n","[ 7, 50176] Train Accuracy: 0.923\n","[ 7, 10240] Test Loss: 0.698\n","[ 7, 10240] Test Accuracy: 0.772\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 8, 50176] Train Loss: 0.180\n","[ 8, 50176] Train Accuracy: 0.935\n","[ 8, 10240] Test Loss: 0.647\n","[ 8, 10240] Test Accuracy: 0.794\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[ 9, 50176] Train Loss: 0.124\n","[ 9, 50176] Train Accuracy: 0.955\n","[ 9, 10240] Test Loss: 0.724\n","[ 9, 10240] Test Accuracy: 0.789\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[10, 50176] Train Loss: 0.110\n","[10, 50176] Train Accuracy: 0.960\n","[10, 10240] Test Loss: 0.966\n","[10, 10240] Test Accuracy: 0.755\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[11, 50176] Train Loss: 0.088\n","[11, 50176] Train Accuracy: 0.967\n","[11, 10240] Test Loss: 0.752\n","[11, 10240] Test Accuracy: 0.792\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[12, 50176] Train Loss: 0.071\n","[12, 50176] Train Accuracy: 0.973\n","[12, 10240] Test Loss: 0.874\n","[12, 10240] Test Accuracy: 0.784\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[13, 50176] Train Loss: 0.058\n","[13, 50176] Train Accuracy: 0.977\n","[13, 10240] Test Loss: 0.775\n","[13, 10240] Test Accuracy: 0.803\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[14, 50176] Train Loss: 0.049\n","[14, 50176] Train Accuracy: 0.981\n","[14, 10240] Test Loss: 0.791\n","[14, 10240] Test Accuracy: 0.809\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[15, 50176] Train Loss: 0.042\n","[15, 50176] Train Accuracy: 0.982\n","[15, 10240] Test Loss: 0.983\n","[15, 10240] Test Accuracy: 0.786\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[16, 50176] Train Loss: 0.042\n","[16, 50176] Train Accuracy: 0.982\n","[16, 10240] Test Loss: 0.882\n","[16, 10240] Test Accuracy: 0.796\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[17, 50176] Train Loss: 0.035\n","[17, 50176] Train Accuracy: 0.985\n","[17, 10240] Test Loss: 0.811\n","[17, 10240] Test Accuracy: 0.807\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[18, 50176] Train Loss: 0.029\n","[18, 50176] Train Accuracy: 0.987\n","[18, 10240] Test Loss: 0.886\n","[18, 10240] Test Accuracy: 0.806\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[19, 50176] Train Loss: 0.028\n","[19, 50176] Train Accuracy: 0.987\n","[19, 10240] Test Loss: 0.873\n","[19, 10240] Test Accuracy: 0.806\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[20, 50176] Train Loss: 0.028\n","[20, 50176] Train Accuracy: 0.987\n","[20, 10240] Test Loss: 0.776\n","[20, 10240] Test Accuracy: 0.811\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[21, 50176] Train Loss: 0.019\n","[21, 50176] Train Accuracy: 0.990\n","[21, 10240] Test Loss: 0.791\n","[21, 10240] Test Accuracy: 0.823\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[22, 50176] Train Loss: 0.015\n","[22, 50176] Train Accuracy: 0.992\n","[22, 10240] Test Loss: 0.836\n","[22, 10240] Test Accuracy: 0.818\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[23, 50176] Train Loss: 0.021\n","[23, 50176] Train Accuracy: 0.989\n","[23, 10240] Test Loss: 0.855\n","[23, 10240] Test Accuracy: 0.817\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[24, 50176] Train Loss: 0.017\n","[24, 50176] Train Accuracy: 0.991\n","[24, 10240] Test Loss: 0.913\n","[24, 10240] Test Accuracy: 0.812\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[25, 50176] Train Loss: 0.018\n","[25, 50176] Train Accuracy: 0.991\n","[25, 10240] Test Loss: 0.890\n","[25, 10240] Test Accuracy: 0.814\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[26, 50176] Train Loss: 0.017\n","[26, 50176] Train Accuracy: 0.991\n","[26, 10240] Test Loss: 0.899\n","[26, 10240] Test Accuracy: 0.818\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[27, 50176] Train Loss: 0.015\n","[27, 50176] Train Accuracy: 0.992\n","[27, 10240] Test Loss: 0.922\n","[27, 10240] Test Accuracy: 0.813\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[28, 50176] Train Loss: 0.015\n","[28, 50176] Train Accuracy: 0.992\n","[28, 10240] Test Loss: 0.953\n","[28, 10240] Test Accuracy: 0.812\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[29, 50176] Train Loss: 0.015\n","[29, 50176] Train Accuracy: 0.991\n","[29, 10240] Test Loss: 0.926\n","[29, 10240] Test Accuracy: 0.818\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[30, 50176] Train Loss: 0.009\n","[30, 50176] Train Accuracy: 0.994\n","[30, 10240] Test Loss: 0.857\n","[30, 10240] Test Accuracy: 0.820\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[31, 50176] Train Loss: 0.005\n","[31, 50176] Train Accuracy: 0.995\n","[31, 10240] Test Loss: 0.854\n","[31, 10240] Test Accuracy: 0.830\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[32, 50176] Train Loss: 0.007\n","[32, 50176] Train Accuracy: 0.994\n","[32, 10240] Test Loss: 1.019\n","[32, 10240] Test Accuracy: 0.805\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[33, 50176] Train Loss: 0.010\n","[33, 50176] Train Accuracy: 0.993\n","[33, 10240] Test Loss: 0.896\n","[33, 10240] Test Accuracy: 0.824\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[34, 50176] Train Loss: 0.018\n","[34, 50176] Train Accuracy: 0.991\n","[34, 10240] Test Loss: 0.923\n","[34, 10240] Test Accuracy: 0.819\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[35, 50176] Train Loss: 0.008\n","[35, 50176] Train Accuracy: 0.994\n","[35, 10240] Test Loss: 0.889\n","[35, 10240] Test Accuracy: 0.821\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[36, 50176] Train Loss: 0.006\n","[36, 50176] Train Accuracy: 0.994\n","[36, 10240] Test Loss: 0.960\n","[36, 10240] Test Accuracy: 0.822\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[37, 50176] Train Loss: 0.012\n","[37, 50176] Train Accuracy: 0.993\n","[37, 10240] Test Loss: 0.862\n","[37, 10240] Test Accuracy: 0.822\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[38, 50176] Train Loss: 0.007\n","[38, 50176] Train Accuracy: 0.995\n","[38, 10240] Test Loss: 0.882\n","[38, 10240] Test Accuracy: 0.825\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[39, 50176] Train Loss: 0.004\n","[39, 50176] Train Accuracy: 0.995\n","[39, 10240] Test Loss: 0.927\n","[39, 10240] Test Accuracy: 0.828\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[40, 50176] Train Loss: 0.004\n","[40, 50176] Train Accuracy: 0.995\n","[40, 10240] Test Loss: 0.894\n","[40, 10240] Test Accuracy: 0.832\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[41, 50176] Train Loss: 0.004\n","[41, 50176] Train Accuracy: 0.995\n","[41, 10240] Test Loss: 0.940\n","[41, 10240] Test Accuracy: 0.826\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["196it [01:08,  2.85it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["[42, 50176] Train Loss: 0.010\n","[42, 50176] Train Accuracy: 0.993\n","[42, 10240] Test Loss: 0.942\n","[42, 10240] Test Accuracy: 0.821\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[43, 50176] Train Loss: 0.011\n","[43, 50176] Train Accuracy: 0.993\n","[43, 10240] Test Loss: 0.888\n","[43, 10240] Test Accuracy: 0.823\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[44, 50176] Train Loss: 0.006\n","[44, 50176] Train Accuracy: 0.994\n","[44, 10240] Test Loss: 1.016\n","[44, 10240] Test Accuracy: 0.817\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[45, 50176] Train Loss: 0.007\n","[45, 50176] Train Accuracy: 0.994\n","[45, 10240] Test Loss: 0.899\n","[45, 10240] Test Accuracy: 0.829\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[46, 50176] Train Loss: 0.005\n","[46, 50176] Train Accuracy: 0.995\n","[46, 10240] Test Loss: 0.885\n","[46, 10240] Test Accuracy: 0.834\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[47, 50176] Train Loss: 0.002\n","[47, 50176] Train Accuracy: 0.996\n","[47, 10240] Test Loss: 0.868\n","[47, 10240] Test Accuracy: 0.833\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[48, 50176] Train Loss: 0.002\n","[48, 50176] Train Accuracy: 0.996\n","[48, 10240] Test Loss: 0.884\n","[48, 10240] Test Accuracy: 0.833\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[49, 50176] Train Loss: 0.006\n","[49, 50176] Train Accuracy: 0.994\n","[49, 10240] Test Loss: 1.134\n","[49, 10240] Test Accuracy: 0.809\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[50, 50176] Train Loss: 0.011\n","[50, 50176] Train Accuracy: 0.993\n","[50, 10240] Test Loss: 0.885\n","[50, 10240] Test Accuracy: 0.829\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[51, 50176] Train Loss: 0.005\n","[51, 50176] Train Accuracy: 0.995\n","[51, 10240] Test Loss: 0.861\n","[51, 10240] Test Accuracy: 0.831\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[52, 50176] Train Loss: 0.005\n","[52, 50176] Train Accuracy: 0.995\n","[52, 10240] Test Loss: 0.881\n","[52, 10240] Test Accuracy: 0.828\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[53, 50176] Train Loss: 0.002\n","[53, 50176] Train Accuracy: 0.996\n","[53, 10240] Test Loss: 0.901\n","[53, 10240] Test Accuracy: 0.833\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[54, 50176] Train Loss: 0.001\n","[54, 50176] Train Accuracy: 0.996\n","[54, 10240] Test Loss: 0.921\n","[54, 10240] Test Accuracy: 0.833\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[55, 50176] Train Loss: 0.001\n","[55, 50176] Train Accuracy: 0.996\n","[55, 10240] Test Loss: 0.880\n","[55, 10240] Test Accuracy: 0.840\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[56, 50176] Train Loss: 0.000\n","[56, 50176] Train Accuracy: 0.996\n","[56, 10240] Test Loss: 0.873\n","[56, 10240] Test Accuracy: 0.840\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[57, 50176] Train Loss: 0.000\n","[57, 50176] Train Accuracy: 0.996\n","[57, 10240] Test Loss: 0.899\n","[57, 10240] Test Accuracy: 0.841\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[58, 50176] Train Loss: 0.000\n","[58, 50176] Train Accuracy: 0.996\n","[58, 10240] Test Loss: 0.857\n","[58, 10240] Test Accuracy: 0.842\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[59, 50176] Train Loss: 0.000\n","[59, 50176] Train Accuracy: 0.996\n","[59, 10240] Test Loss: 0.885\n","[59, 10240] Test Accuracy: 0.843\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[60, 50176] Train Loss: 0.000\n","[60, 50176] Train Accuracy: 0.996\n","[60, 10240] Test Loss: 0.915\n","[60, 10240] Test Accuracy: 0.844\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[61, 50176] Train Loss: 0.000\n","[61, 50176] Train Accuracy: 0.996\n","[61, 10240] Test Loss: 0.910\n","[61, 10240] Test Accuracy: 0.844\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:09,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[62, 50176] Train Loss: 0.000\n","[62, 50176] Train Accuracy: 0.996\n","[62, 10240] Test Loss: 0.873\n","[62, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:09,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[63, 50176] Train Loss: 0.000\n","[63, 50176] Train Accuracy: 0.996\n","[63, 10240] Test Loss: 0.867\n","[63, 10240] Test Accuracy: 0.846\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[64, 50176] Train Loss: 0.000\n","[64, 50176] Train Accuracy: 0.996\n","[64, 10240] Test Loss: 0.873\n","[64, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[65, 50176] Train Loss: 0.000\n","[65, 50176] Train Accuracy: 0.996\n","[65, 10240] Test Loss: 0.888\n","[65, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[66, 50176] Train Loss: 0.000\n","[66, 50176] Train Accuracy: 0.996\n","[66, 10240] Test Loss: 0.878\n","[66, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[67, 50176] Train Loss: 0.000\n","[67, 50176] Train Accuracy: 0.996\n","[67, 10240] Test Loss: 0.887\n","[67, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[68, 50176] Train Loss: 0.000\n","[68, 50176] Train Accuracy: 0.996\n","[68, 10240] Test Loss: 0.897\n","[68, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[69, 50176] Train Loss: 0.000\n","[69, 50176] Train Accuracy: 0.996\n","[69, 10240] Test Loss: 0.914\n","[69, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:09,  2.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[70, 50176] Train Loss: 0.000\n","[70, 50176] Train Accuracy: 0.996\n","[70, 10240] Test Loss: 0.899\n","[70, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[71, 50176] Train Loss: 0.000\n","[71, 50176] Train Accuracy: 0.996\n","[71, 10240] Test Loss: 0.892\n","[71, 10240] Test Accuracy: 0.844\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[72, 50176] Train Loss: 0.000\n","[72, 50176] Train Accuracy: 0.996\n","[72, 10240] Test Loss: 0.928\n","[72, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[73, 50176] Train Loss: 0.000\n","[73, 50176] Train Accuracy: 0.996\n","[73, 10240] Test Loss: 0.900\n","[73, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[74, 50176] Train Loss: 0.000\n","[74, 50176] Train Accuracy: 0.996\n","[74, 10240] Test Loss: 0.884\n","[74, 10240] Test Accuracy: 0.846\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[75, 50176] Train Loss: 0.000\n","[75, 50176] Train Accuracy: 0.996\n","[75, 10240] Test Loss: 0.887\n","[75, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[76, 50176] Train Loss: 0.000\n","[76, 50176] Train Accuracy: 0.996\n","[76, 10240] Test Loss: 0.922\n","[76, 10240] Test Accuracy: 0.846\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[77, 50176] Train Loss: 0.000\n","[77, 50176] Train Accuracy: 0.996\n","[77, 10240] Test Loss: 0.929\n","[77, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[78, 50176] Train Loss: 0.000\n","[78, 50176] Train Accuracy: 0.996\n","[78, 10240] Test Loss: 0.922\n","[78, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[79, 50176] Train Loss: 0.000\n","[79, 50176] Train Accuracy: 0.996\n","[79, 10240] Test Loss: 0.909\n","[79, 10240] Test Accuracy: 0.845\n"]},{"output_type":"stream","name":"stderr","text":["196it [01:08,  2.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["[80, 50176] Train Loss: 0.000\n","[80, 50176] Train Accuracy: 0.996\n","[80, 10240] Test Loss: 0.904\n","[80, 10240] Test Accuracy: 0.844\n","[1.40666156186133, 0.8332906006550302, 0.6077227543811409, 0.46742488687135736, 0.3662230696301071, 0.2807674648202195, 0.21493795042743488, 0.18018387254251508, 0.12424715353670168, 0.10963830125651189, 0.08758355987885473, 0.07112528568095698, 0.05765486833145272, 0.0486488381486234, 0.041610374904180666, 0.04163345575275622, 0.03453756588967327, 0.028865786232481882, 0.027978513557321335, 0.027612552217835068, 0.019376123229597638, 0.014959357600488072, 0.02117907021750639, 0.017067622090749232, 0.017571368521555775, 0.01727375387551491, 0.01456742866169091, 0.015270360937337297, 0.015184479813704419, 0.008995889034033136, 0.005365769404974975, 0.007481309945061946, 0.010428300180397596, 0.017583923103413734, 0.008311317235615096, 0.005993896966434217, 0.01166478907792652, 0.0069481559355840635, 0.003756215730687955, 0.004417144415574326, 0.0043402038374960265, 0.009909936653067624, 0.01066403331075277, 0.006201789843729859, 0.006965797948080818, 0.004855991107303582, 0.00183860988413564, 0.001685429612354376, 0.006449987368072545, 0.010651396576799832, 0.005359693206405702, 0.005371081198935993, 0.0021225553164742673, 0.001490768519200786, 0.000625242341579813, 0.0003177018182780056, 0.0001291844596102126, 9.67617713392744e-05, 5.848990404928725e-05, 0.00018433994697790362, 5.345083088184542e-05, 3.591698929753597e-05, 2.8578914740434383e-05, 2.762491753020761e-05, 2.2912988175467408e-05, 2.068913884228578e-05, 1.693329232747304e-05, 1.72367768785228e-05, 1.6899131100337992e-05, 1.6127760173332013e-05, 1.355213690050398e-05, 1.363351558856433e-05, 1.5986685262268278e-05, 1.3789292061536966e-05, 1.0765350600765989e-05, 1.1069157386716644e-05, 1.2775606604946563e-05, 1.1674208234562313e-05, 1.0292720055670599e-05, 9.776257506789024e-06]\n","[0.47544642857142855, 0.7059550382653061, 0.7869300063775511, 0.8374123086734694, 0.8739237882653061, 0.9015066964285714, 0.9233697385204082, 0.9354671556122449, 0.955436862244898, 0.9600406568877551, 0.9670360331632653, 0.9725366709183674, 0.977180325255102, 0.9805484693877551, 0.9820033482142857, 0.9822026466836735, 0.9847138073979592, 0.9872648278061225, 0.9865872130102041, 0.9869260204081632, 0.9903340242346939, 0.9918885522959183, 0.9892777423469388, 0.9909119897959183, 0.9907525510204082, 0.9905133928571429, 0.9916294642857143, 0.9916892538265306, 0.9912109375, 0.9936025191326531, 0.9946787308673469, 0.9942004145408163, 0.9934630102040817, 0.9908721301020408, 0.9939213966836735, 0.9944794323979592, 0.9927654655612245, 0.9945790816326531, 0.9953164859693877, 0.9950175382653061, 0.9952566964285714, 0.9934829400510204, 0.9931640625, 0.9943797831632653, 0.9942602040816326, 0.9947983099489796, 0.9958346619897959, 0.9960738201530612, 0.9944595025510204, 0.9930843431122449, 0.9949178890306123, 0.9949577487244898, 0.9957549426020408, 0.99609375, 0.9963129783163265, 0.9964126275510204, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964325573979592, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755]\n","[0.59091796875, 0.67099609375, 0.7130859375, 0.7615234375, 0.76513671875, 0.78037109375, 0.7720703125, 0.79375, 0.7890625, 0.7552734375, 0.7921875, 0.78408203125, 0.8033203125, 0.80859375, 0.78564453125, 0.79609375, 0.8072265625, 0.80556640625, 0.80595703125, 0.81064453125, 0.8232421875, 0.81796875, 0.81689453125, 0.8125, 0.814453125, 0.817578125, 0.81318359375, 0.8115234375, 0.818359375, 0.819921875, 0.82958984375, 0.805078125, 0.82412109375, 0.819140625, 0.82060546875, 0.8224609375, 0.822265625, 0.825, 0.8275390625, 0.831640625, 0.826171875, 0.82080078125, 0.82294921875, 0.8171875, 0.82880859375, 0.834375, 0.833203125, 0.83310546875, 0.8087890625, 0.82880859375, 0.83125, 0.82802734375, 0.8333984375, 0.83310546875, 0.8396484375, 0.83974609375, 0.8408203125, 0.84208984375, 0.8431640625, 0.84404296875, 0.84384765625, 0.84482421875, 0.84609375, 0.84453125, 0.84501953125, 0.84462890625, 0.84501953125, 0.844921875, 0.84482421875, 0.84541015625, 0.8443359375, 0.844921875, 0.8447265625, 0.8458984375, 0.8453125, 0.84599609375, 0.84482421875, 0.84462890625, 0.8451171875, 0.8443359375]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/serialization.py:405: UserWarning: Couldn't retrieve source code for container of type VGG16. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":541},"id":"pTgF6BpSaEBr","executionInfo":{"status":"ok","timestamp":1636733463848,"user_tz":-480,"elapsed":1115,"user":{"displayName":"邱宜靜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYSQb7ldadtujLNYX93PbE2EKEFM2fI4X2ycdfsg=s64","userId":"01336892841119909216"}},"outputId":"9c496211-a0a4-4d53-8ba8-787810b13f7f"},"source":["import matplotlib.pyplot as plt\n","loss_epochs = [1.40666156186133, 0.8332906006550302, 0.6077227543811409, 0.46742488687135736, 0.3662230696301071, 0.2807674648202195, 0.21493795042743488, 0.18018387254251508, 0.12424715353670168, 0.10963830125651189, 0.08758355987885473, 0.07112528568095698, 0.05765486833145272, 0.0486488381486234, 0.041610374904180666, 0.04163345575275622, 0.03453756588967327, 0.028865786232481882, 0.027978513557321335, 0.027612552217835068, 0.019376123229597638, 0.014959357600488072, 0.02117907021750639, 0.017067622090749232, 0.017571368521555775, 0.01727375387551491, 0.01456742866169091, 0.015270360937337297, 0.015184479813704419, 0.008995889034033136, 0.005365769404974975, 0.007481309945061946, 0.010428300180397596, 0.017583923103413734, 0.008311317235615096, 0.005993896966434217, 0.01166478907792652, 0.0069481559355840635, 0.003756215730687955, 0.004417144415574326, 0.0043402038374960265, 0.009909936653067624, 0.01066403331075277, 0.006201789843729859, 0.006965797948080818, 0.004855991107303582, 0.00183860988413564, 0.001685429612354376, 0.006449987368072545, 0.010651396576799832, 0.005359693206405702, 0.005371081198935993, 0.0021225553164742673, 0.001490768519200786, 0.000625242341579813, 0.0003177018182780056, 0.0001291844596102126, 9.67617713392744e-05, 5.848990404928725e-05, 0.00018433994697790362, 5.345083088184542e-05, 3.591698929753597e-05, 2.8578914740434383e-05, 2.762491753020761e-05, 2.2912988175467408e-05, 2.068913884228578e-05, 1.693329232747304e-05, 1.72367768785228e-05, 1.6899131100337992e-05, 1.6127760173332013e-05, 1.355213690050398e-05, 1.363351558856433e-05, 1.5986685262268278e-05, 1.3789292061536966e-05, 1.0765350600765989e-05, 1.1069157386716644e-05, 1.2775606604946563e-05, 1.1674208234562313e-05, 1.0292720055670599e-05, 9.776257506789024e-06]\n","train_acc_epochs = [0.47544642857142855, 0.7059550382653061, 0.7869300063775511, 0.8374123086734694, 0.8739237882653061, 0.9015066964285714, 0.9233697385204082, 0.9354671556122449, 0.955436862244898, 0.9600406568877551, 0.9670360331632653, 0.9725366709183674, 0.977180325255102, 0.9805484693877551, 0.9820033482142857, 0.9822026466836735, 0.9847138073979592, 0.9872648278061225, 0.9865872130102041, 0.9869260204081632, 0.9903340242346939, 0.9918885522959183, 0.9892777423469388, 0.9909119897959183, 0.9907525510204082, 0.9905133928571429, 0.9916294642857143, 0.9916892538265306, 0.9912109375, 0.9936025191326531, 0.9946787308673469, 0.9942004145408163, 0.9934630102040817, 0.9908721301020408, 0.9939213966836735, 0.9944794323979592, 0.9927654655612245, 0.9945790816326531, 0.9953164859693877, 0.9950175382653061, 0.9952566964285714, 0.9934829400510204, 0.9931640625, 0.9943797831632653, 0.9942602040816326, 0.9947983099489796, 0.9958346619897959, 0.9960738201530612, 0.9944595025510204, 0.9930843431122449, 0.9949178890306123, 0.9949577487244898, 0.9957549426020408, 0.99609375, 0.9963129783163265, 0.9964126275510204, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964325573979592, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755, 0.9964923469387755]\n","test_acc_epochs = [0.59091796875, 0.67099609375, 0.7130859375, 0.7615234375, 0.76513671875, 0.78037109375, 0.7720703125, 0.79375, 0.7890625, 0.7552734375, 0.7921875, 0.78408203125, 0.8033203125, 0.80859375, 0.78564453125, 0.79609375, 0.8072265625, 0.80556640625, 0.80595703125, 0.81064453125, 0.8232421875, 0.81796875, 0.81689453125, 0.8125, 0.814453125, 0.817578125, 0.81318359375, 0.8115234375, 0.818359375, 0.819921875, 0.82958984375, 0.805078125, 0.82412109375, 0.819140625, 0.82060546875, 0.8224609375, 0.822265625, 0.825, 0.8275390625, 0.831640625, 0.826171875, 0.82080078125, 0.82294921875, 0.8171875, 0.82880859375, 0.834375, 0.833203125, 0.83310546875, 0.8087890625, 0.82880859375, 0.83125, 0.82802734375, 0.8333984375, 0.83310546875, 0.8396484375, 0.83974609375, 0.8408203125, 0.84208984375, 0.8431640625, 0.84404296875, 0.84384765625, 0.84482421875, 0.84609375, 0.84453125, 0.84501953125, 0.84462890625, 0.84501953125, 0.844921875, 0.84482421875, 0.84541015625, 0.8443359375, 0.844921875, 0.8447265625, 0.8458984375, 0.8453125, 0.84599609375, 0.84482421875, 0.84462890625, 0.8451171875, 0.8443359375]\n","plt.plot(loss_epochs, label='train_loss')\n","plt.xlabel('epoch')\n","plt.ylabel('loss value')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(train_acc_epochs, label='train_acc')\n","plt.plot(test_acc_epochs, label='test_acc')\n","plt.xlabel('epoch')\n","plt.ylabel('acc value')\n","plt.legend()\n","plt.show()\n"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXyU9bX48c+Zyb6QQAj7KrIvAVkVqQtV0ba4r9VW22Jbl2ut16terVt/9npvrdZet6K1VmtVtNZLFTcUpCpqABFZZN8SthDIvs7M+f3xnZAQkjCETGbCnPfrlReZZ5555mQSnvM857uJqmKMMSZ2eSIdgDHGmMiyRGCMMTHOEoExxsQ4SwTGGBPjLBEYY0yMi4t0AEeqa9euOmDAgEiHYYwxHcrSpUv3qmp2U891uEQwYMAAlixZEukwjDGmQxGRrc09Z6UhY4yJcZYIjDEmxlkiMMaYGGeJwBhjYlzYEoGIPCsie0RkZTPPi4j8QUQ2iMgKETkhXLEYY4xpXjjvCJ4DZrTw/NnA4ODXtcCTYYzFGGNMM8KWCFR1EbCvhV3OBZ5X5zMgU0R6hiseY4wxTYvkOILewPYGj/OC23Y23lFErsXdNdCvX792Cc6YpqgqFTV+PCIkxHnweuSg53wBRRUS4truGktVKa32saekij2l1VT7AtT6AvgCigD9s1I5LjuVpHjvER87EFBKq3zsq6hhf0UNVTV+qnx+qmoDVPv81PqVWn8AX/DfgCoBBX9A0eD3ddsIYUp7EcEjgojbPaCKEtprDUwf3p2cvpltftwOMaBMVWcDswEmTJhgfzExZl95DUu27GNDQRm7i6vYVVLF7pJqAqqkJHhJTYgjJTGOjOQ4MpMTyEyJJystgZw+mQzsmopI/cm6tKqWRev28lVeEaVVtZRW+Sir9hHn8TC4expDuqcxuFs6qrBmVwlrd5Wydlcpu0uq2F9RS3FlDbX++j/BOI8Q7/XgDyg1/gAAItC3cwpDe6QzrEc6A7JSSU7wkhjnITHOS1Wtnx3FleTvryS/qJLKGj8igtcDXo9QXRugtNpHWTC2gtJqKmv9LX5Gde85KDuV/lmp9O2SQv8uKSjwzc4S1uwq4ZudpRRV1qLBk68qlFX78Afa5r9Ug4+5SS2d6w/3WuN065R0zCWCfKBvg8d9gttMlPD5A6zeWcLGgjI2FZSzqaCcal+ASQM7c9Kgrgzv2cmduHx+Nu8tZ+OecsqrfXg9QpxX8AZPkgleD/FeDx4PFJbVsLO4kp3FVewtq8EfCBAIgKIIQkqCl5REd3Ivrqwld8s+NhaUH4gpPSmOHp2S6JGRhNcjVFT72VVSRXm1j+LKWoora2l4XuvRKYkpx3VhcPd0Fm8s5PPNhdT6lYQ4DxnJ8aQnxpGWFEdljZ+Fa/fga3RSTIr3MKR7Osd3SyMzJZ7MlAQykuNRhRpf3VVzAK/HQ4LX/by1AWXDHpdAPlizm+bOswleD70yk0hLisMfcFfnflUS4zykJcbRKzOJ1MQ4stMS6d4piW6dEslOSyQpwXvgM631B9i8t5wNe8rYEPw95W7ZT1m176D36p+VwrAe6WSnJyK4K3IB0pLi6JySQJfUBDqnJJCc4CUp3ktSvPu9JcS594n3ursfr0fwBq/oPeIee4SDkm1LVPXAnUDdnUGorzXhE8lEMBe4QUReBiYDxap6SFnItC1VbfE/ns8f4PPN+3hzxU7eXbWLfeU1gLtS7ds5GY8I89fsBiAjOZ7OKfFs21fR7MmuOSkJXrqlJxLv9Rw4qQSCZZeKGj/l1T6S4r2M79+ZC8f3YeKALozo2YnUxJb/ZOtKHbtLq8jdso/FGwv5eMNe3li+g+O7pfGjqQOZPrw7J/TLJM57cPmmxhdgS2E563aX4hVhaI90+melHlT+OVJVtX52FldR7fNTXRug2hcg3iv07pxM19REPEdx7Dqjemcc9FhV2Vdew9Z9FQAM7Z5+2M+tvUhdEsFO/tFEwrVUpYi8BJwKdAV2A/cA8QCq+pS4s9FjuJ5FFcA1qnrYSYQmTJigNtdQ6Hz+AKt2lPDZpkIWbypkyZb91PoDZCTHk5EcT6fkePwBparWT40vwN6yakqqfKQkeJk+vDtnjujO8J7p9OuSeqDuvbukisUbC1m8sZDS6lqOz05jULc0ju+WRkbweL6A4vMrvkDgQJ251h+ga1oiPTKSSE+Ma7crQVWlqKKWzqkJ7fJ+xkQjEVmqqhOafK6jrVlsieBQPr9rOHQnW2Xbvgo+21TI55sKDyoTDMpOZfJxWaQlxlFc4cooJVW1eD1CUryrYacnxfGtwdmcOrQbyQlH3vhojIlOLSWC6LhfNCFRVb7KK+bj9QVs2lvOlr3lbCmsOFC+aWxQdiozx/ZiynFZTDmuC93Sk9o5YmNMR2CJIMrVnfzfWrGDeV/vIr+oEoCeGUkMyErlrJHd6dEpOdioJ8R5hOz0JCYO7GwnfmNMSCwRRCl/QHln5S5mL9rIV3nFxHuFaYOzufmMIZwxvDsZKfGRDtEYc4ywRBBlanwBXlmynacXbWLbvgoGZKXw6/NGMTOnFxnJdvI3xrQ9SwRRIhBQ/rliBw+9t5bt+yoZ1y+T/zxnGGeM6HFU3ReNMeZwLBFEgU837uU389awMr+E4T078ZcfjeZbg7vaQBtjTLuwRBBBFTU+fjNvDX/9bBu9M5N55NIczs3p3SaDjIwxJlSWCCJk6db93DJnOVv3VTBr2kBuOXNoqyYNM8aYo2WJoJ3tLK7k6UWbee7TzfTMSOalWVOYclxWpMMyxsQwSwTtZPWOEp751ybmfrUDBS6Z0Jc7vzOc9CTrCWSMiSxLBO3g9/PX8fv560lJ8PKDEwdwzdQB9O2SEumwjDEGsEQQdjuLK3li4UbOGtmd/7kwxwaCGWOiTjjXLDbAEws2oqrc9Z0RlgSMMVHJEkEY5e2v4OXcbVwyoa+VgowxUcsSQRg9vmADgnD9acdHOhRjjGmWJYIw2VZYwatL8rh8Ul96ZSZHOhxjjGmWJYIw+d8P1+P1CNfZ3YAxJspZIgiDzXvLef3LfK6c0p/unWxNAGNMdLNE0Maqav38cs5yEuM8/OyUQZEOxxhjDsvGEbQhVeW2v6/gy21FPHXlCWSnJ0Y6JGOMOSy7I2hDj324gf9bvoNbzxrKjFE9Ix2OMcaExBJBG3lrxU5+9/46LjihN9edaiUhY0zHYYmgDazbXcotry5nQv/O/NcFo21BGWNMh2KJoA08+sF64j0enrpqPIlxtqaAMaZjsURwlLYWlvP21zv5/pT+dE2zxmFjTMdjieAozV60iTiPhx9NHRDpUIwxplUsERyFgtJqXl2ax4Xje9PNBo4ZYzooSwRH4blPN1PrDzBr2nGRDsUYY1rNEkErlVX7eGHxVs4a0YPjstMiHY4xxrRaWBOBiMwQkbUiskFEbm/i+f4i8oGIrBCRhSLSJ5zxtKWXv9hGSZWPn9mYAWNMBxe2RCAiXuBx4GxgBHC5iIxotNtDwPOqOga4H/ivcMXTlmp8AZ7512amHNeFsX0zIx2OMcYclXDeEUwCNqjqJlWtAV4Gzm20zwjgw+D3C5p4PirNX7ObXSVVXPstaxswxnR84UwEvYHtDR7nBbc19BVwQfD784F0EclqfCARuVZElojIkoKCgrAEeyReX5ZH906JnDKkW6RDMcaYoxbpxuJ/B04RkS+BU4B8wN94J1WdraoTVHVCdnZ2e8d4kL1l1SxcW8B543rj9dhUEsaYji+c01DnA30bPO4T3HaAqu4geEcgImnAhapaFMaYjto/v9qBL6BcMK7DtGsbY0yLwnlHkAsMFpGBIpIAXAbMbbiDiHQVkboY7gCeDWM8beLvy/IY1bsTQ3ukRzoUY4xpE2FLBKrqA24A3gXWAHNUdZWI3C8iM4O7nQqsFZF1QHfggXDF0xbW7iplZX6J3Q0YY44pYV2hTFXnAfMabbu7wfevAa+FM4a29PqXecR5hJlje0U6FGOMaTORbizuMPwB5Y0v8zl1aLbNMmqMOaZYIgjRJxv2srukmgtOsLKQMebYYokgRK8vy6NTUhzTh9vYAWPMscUSQQgqany8s2oX383pZSuQGWOOOZYIQvD5pn1U1QY4e1SPSIdijDFtzhJBCD5aV0BSvIeJA7pEOhRjjGlzlghCsGhdAZMHZpEUb2UhY8yxxxLBYWzfV8GmveV8a0hk5zgyxphwsURwGIvWu9lOTxnSNcKRGGNMeFgiOIxF6wrolZHEIFuO0hhzjLJE0IJaf4BPNxRyytBsRGzKaWPMsckSQQuWby+itNrHtwZb+4Ax5thliaAFH60twOsRTjre2geMMceusM4+2tEtWl/A2L6ZZCTHRzoUY2KL3welO6Bom/vyVUHW8ZA1GNJ7QF2pVhX8NSAe8Dbx/zQQcK8VcfuI1/3raXANrAq1FVBVAtWlbt/0HpDYxJojqu7fhqXi2koozoeSPCjdDfFJkNgJkjpBXDJUl0BlEVTuh4APOvWCjL6Q0RsSUpv5+Wuhpsy9Pj6pdZ/hEbBE0Ix95TV8nV/ML6YPiXQoxnRMfh+U74GSne6kXrYHyvdCeQFUFAIKnvjgCVzc9rLdwa89oIesWuskpENSBtSUQk25O7kCeOLqT5wBnztB+6qaj68uMWig6fdKSIdOPcGbEEwSwUSh/vq4xeviaK24ZHccj9cdM1DrfiZ/Tf0+8amQkgUpnWHaLTDi3Na/X3NhtPkRjxH/Wl+AKpwy1NoHjAHc1XXdSVMD7oRVsgNKd7p/S/Lrr+CLtrntGjj0OMmd3YkNcSc+vw9Qty29B/QYBek9IbNf/ZcnHgo3wN71ULgeqssgMc1dUSekguKu6msrwVfp9o9PhvgUiAtOG6/B+AP++u/V7xJCYnrwKj7DbW/4cwV89Vf4ienu5B+odVftAT+kZkGnPpDRx8Xvq6q/u6itcMdMznQ/t3jdMYvzoHh7/V2Cv9ad/L3xkJAW/Ep1r6/c7xJnRaFLHGFgiaAZi9btJTMlntG9MyIdijGRVVkE7/8Kvvxr0yf2OuJxJ8TMfjDwW8ETY09XCknv6U6SKVlNl3BCkdkXBp3WutdGk879Ix3BISwRNOOTDXuZenxXvB7rNmpi2Oq5MO/fXUnnhB+4E72IK2XEJbvSSXov929aD/DaKaUjst9aE3aXVLGrpIrx/TpHOhQTq2or4bMn4NP/deWEjD71V9hxicHGTy+kdYPJPz+48bM19q6HL552pYi4RPAmwr6NsO4d6DEarpgDvca2zc9moo4lgiZ8nVcMwOg+VhaKWtWl7mQVlxC5GHZ8CUv+DBs/hOEzXUNeatbRHTPgh69ehgUPuJr74LPc1XZxHhRuhC0fu5qyBoK15RroMgiGzmj6eDUVkJcLWz+F7Z+5Wvew78KQs1zdujgPFj4Iy//mSjbJncFX7Y7r8cL0e+CkG1tfzjEdgiWCJnydX4xHYETPTpEOxTRley68eCEMPQfOf6r93lcV9m92J/5lL8DO5a480m8yfP4kfPkCTL0Jpvy8+W6BLakqhhcugPwl0Hs8XPA0DJja/P7+WnhkFOQ+3XQi+Oi38NGDwV41At1HQcFaWDPX9bDpMxHylwEKk2bBtH+HNOscEYssETTh6/xiBmWnkZpoH0/U2bwI/naZ6xny9avw7fsgvfuh+9VUQELK0b9fcR5sXABb/uWuxkvy3fZuI+Ds38KYS9yV9Z5v4IP74cNfuxLLKbfCCT8M/UraXwtzfuCSy/l/hDGXHtxXvSneeBh/tTvZF26ErEH1zxVtg4/+G447FSb9FPpOcnEGApC/FL75J2z4EEZfBKfe7hp4TcyyM10jqsrX+cVMG2yjidnyCSx+DCb+GAZNP/yJKdzWvQdzroLOA+A7D8Nz58Cy591Jt6EdX8KfzoQ+k+CU/3A9WJqKvbYKCtbA7lVQustdJXvjXdfDvetg0wLXZREgNRsGnBz8mgZdhxx8zG7D4PK/wbbPYP698NYtrr5/2l0w6gIo2uquvvOXuruFE693ZRhwdxr/vAk2LYRzn4Ccy0L/TMZfDf96CJY8C2c9UL990UMuvu896toW6ng80Hei+zrj/tDfxxzTLBE0srukmoLSasbEerfR/VvglStdH+a186DfSTD9V9D/pPaLwe9zJ9C9692V8qKHoPsIuPIfrhY/6HRY+mc4+eaDe6u8f4/rP75vIzw/E/pOhknXun7v+zbCvk3umHvXNz9oKT4F+k+FCT9yV9XdRoSWCPtNgWvehvXvuzuE138Cc2+oH9gUl+Tq77nPwKl3uOP/63ew/EU45XYY9/0j+4w69XQ1/y9fgNPudHdB+za740340cFJwJhmWCJo5Ot8ayimphxevtKdJK9b7Eoiix6CP58NvU6ALsfVdxvsNc6d/Fo6SVaXwoYPYNtid0U99BzXENmcyv3wzn+60k+gtn77gGlw2YtugA7AxJ/Ay1fAurdh+Pfcto0LYPNHMONBGH+NO0F+/Hv4+4/d85546DLQTVcw/Huubt5jNHTq7X5ef239AKLWNkSLwJAz4fhvw6rX3c/dfZSr+3cb7ur07/4nvP0f8OljULwNcq5wJZrWmDQLVr8BK19zXTwXPeR6FJ38y9Ydz8Qc0bq5MzqICRMm6JIlS8J2/IffW8tjCzaw6r4ZJCfE4NKUqvDaj2DVP+D7r8Hgb7vtNRXuKnbt2266gJKd4K92z3UfDZN/CqMvdsP7aypcuWXHl7D+PXdi9tcEh/P7XT160rUw7ipXt25o3bsw99/cdAPjr3Ynz66D3Yk7pdGa0QE/PJrjauM/+D9X/376NKjYBzcuqR9R6quBHcvcgKaMvi0nofai6j7L+fe4UtelL7Y+8ajCEye6stbFz8FjE93vY8Z/tWXEpoMTkaWqOqHJ5ywRHOyaP3/BjqIq3r35W2F7j6j28SOuxv3te13JpTmq7oT7zZvw+VOwZ3VwPpSubgqAuhGonQfA0O/AsHNcL5V178BnT8G2T133z+yhkD0MsodA4Sb46m+uDHPek6H1W1/0kGugvWEJ7F4Jr14N5z0FYy8/6o+i3agefftL7jOuXaLnWHfHcdNXTTeim5hliSBEqsrEB+Zz6tBuPHRxTlje46j5fW4OlMy+bXvcPd+4xs3lL8LI8+GiZ0M/Oam6XjW5f3J90HuOgR5j3L8ZfZs+zs6vXOlnzxp34ire7qYoOPlmOOW2+qv5wynbAw+PcHcPGz90r/vZx9Fx1d+eqkvhd8PdBGgn3Qhn/r9IR2SiTEuJwNoIGthVUsXespronF8oEHD15gW/cX3Zr/3InWhbogqLH3dlmoZX3nHJ9RN0le5yV5Pr3nbbJ//UDSI6kitUEdczZ+AR3EX1zHFfdarLXINq6hH21krr5mZjzH3aPb785dhLAuAmQzvhB65N5KSbIh2N6WDCmghEZAbwKOAFnlHVBxs93w/4C5AZ3Od2VZ0XzphasiJaRxSvfRs++DXsWeXKJnHJbvqBww2m+uh/YOFvXDfFr/7W/H7JXVwPlomzjn5kbGslprmv1pj4E9dQ2ncyDGlmhG0s+Pa9cPIvbFCYOWJhSwQi4gUeB84A8oBcEZmrqqsb7HYXMEdVnxSREcA8YEC4YjqclfnFeD0SXSOK174NL13mphG48E8w8gJ45zY3tcG373UNoE3J/ZNLAmOvhHMfg6oiKFjn+scHfK57ZHyy69Pe78S2GXwVKf2muM9iyNmRH+sQSXEJ7g7JmCMUzjuCScAGVd0EICIvA+cCDROBAnVn3QxgRxjjOawVecUM7pZGUnyUlBYCfph/n1uV6brF9aNUJ//MjV7NfQZOv+vQ1616wzUcDjnbDSgScXcF/Sa7r2ONSMsN28aYFoVzzeLewPYGj/OC2xq6F7hSRPJwdwM3NnUgEblWRJaIyJKCgoJwxIqqsjK/OLraB1bMcSNfT7/z4KkKsga5vvi5f3J1/oY2LYTXZ7kyyUXP2rTAxpjDivTi9ZcDz6lqH+Ac4AUROSQmVZ2tqhNUdUJ2dnjqnzuKqygsr2FMW7QPFKyDhf8NRdsPv29zfDWutNMzB4Y3sTTdiddB5T43U2WdrYvhpctdn/srXu7Y5R5jTLsJORGIyJGeVfKBhn0c+wS3NfRjYA6Aqi4GkoCITPJTN/X0qLa4I3j7VncSfzQHXr8Wdq1sfl9V+PM58PefuJ4zdZY+5yYOm35303PN95/qksRnT7oeRXlL4MWL3QjZH/xf/Tw2xhhzGIdNBCJykoisBr4JPs4RkSdCOHYuMFhEBopIAnAZMLfRPtuA6cHjDsclgvDUfg7j6/wi4jzC8KNtKM5f5sozJ97gavlr3oSnprqafVMK1sLWT1yf+j+d4WaRrCmHRb91UyoMmt7060RgyvWwdy18/LCbvji1K/xwrjUYGmOOSCh3BI8AZwGFAKr6FXDYDuOq6gNuAN4F1uB6B60SkftFZGZwt1uAWSLyFfAScLVGaITbyvwSBndPP/qG4k9+D4kZblDUjN/AzSth1EVudsjywkP33/iB+3fmY26g2NOnwRvXQfmew/fnH3m+Wx7ww1+7+Xd++E+3PqwxxhyBkEpDqtq42N3MlI2HvG6eqg5R1UGq+kBw292qOjf4/WpVnaqqOao6VlXfO6Lo29DWwnIGZbdiMZGGCje6NV4n/hiSgncWKV3clMMacPPuNLbxQzel8QlXwbUL3Ujc1W+4xuC+E1t+v7gEOO0/odtIdyfQ1qONjTExIZREsF1ETgJUROJF5N9xV/jHjEBAyS+qpE/nEJtBfNXuCr+sURXrk0fBm+BWqGqo51h35b7u7YO311a5Of8Hne4edx4AP37PLbZyzkOhxTL+h3Ddp25GTWOMaYVQEsHPgOtxXT/zgbHBx8eMPaXV1PqVPp2TQ3vBwgfhzZtdGWfnCretZCd89RKMu/LQGr3H49aI3fCh6w1UZ9tit9JWXSIAN8Dr5F9ARuOetsYYEx6HTQSquldVv6+q3VW1m6peqapNFLs7rrz9FQChJYL8pa4dYPBZrtzz7FluyubPnnAjdk9qcigEDD3bTQi29eP6bRs/dPPjDzi5DX4KY4xpncOONhKRP+NGAB9EVX8UlogiIG+/G5R12NKQr9o15Kb1gAtmu8dzrnJTH3sTXONtcyWagae41anWvlN/B7DxQzc9QmsWOjfGmDYSSmnoTeCt4NcHuCkhylp8RQcT8h3Bwgeh4BuY+Qe3oEp6d9dTZ9yVwGGmOUhIcUsernvbjR0o3eXmzz++me6hxhjTTg57R6Cqf2/4WEReAj5uZvcOKW9/JV3TElvuOlpXEhp3JQw+o357XCKc+zic/dvDj+QdMsMtzLJnjZuPHw5uHzDGmAhozUQ0g4FjasRS3v7K5u8Gqsvc4u0LfuNKQmc+0PR+oUznUDdF8rq33UIwKV3dMo/GGBNBobQRlOLaCCT47y7gtjDH1a7y9lccOrVE/jLXAPzNW24Rl4y+cOHTh66xeyQ69XRdSde+Dfu3uLuBpqaPMMaYdhRKaSi9PQKJFH9wDMHZo3vWbwwE4K8Xul5BYy6FMZdA3yltc9IeejYsDC4qbmUhY0wUaDYRiMgJLb1QVZe1fTjtb09p1aFjCPZtdDN7znzMjfhtS0NmNEgEp7XtsY0xphVauiP4XQvPKXBMXM422XU0P5jjeo9v+zfsmQPpvdzUE82tLmaMMe2o2USgqjFxudpk19H8pRCf6hZ8b2sibsGYuIS2P7YxxrRCSL2GRGQUMAI3TTQAqvp8uIJqT3n73B1B78xGiaDXWPCEacnK/ieG57jGGNMKoaxHcA/wv8Gv04D/AWa2+KIOJG9/JdnpDcYQ+Gpg1wro3WITiTHGHDNC6QZzEW7xmF2qeg2Qg1to/piQV1RxcFlozyrw10AvSwTGmNgQSiKoVNUA4BORTsAeDl6CskNzg8kaNhQvdf+Go6HYGGOiUCiJYImIZAJPA0uBZcDisEbVTvwBZUdRo1HF+cvciN/MfpELzBhj2lEoA8quC377lIi8A3RS1RXhDat9NDmGIH+Zax9oaYlIY4w5hoTSWDxXRK4QkVRV3XKsJAGA7fsajSGoLnWzi1pZyBgTQ0IpDf0OOBlYLSKvichFIpJ0uBd1BHVjCPrW3RHsWA6oJQJjTEwJpTT0EfCRiHhxo4lnAc/i1iXo0OpGFfeqG0OwIzii2HoMGWNiSKgDypKB7wGXAicAfwlnUO0lb38F3RqOIchfCpn9ITUrsoEZY0w7CmUa6jnAJOAd4DHgo2B30g7vkHUI8pdBn4mRC8gYYyIglDuCPwGXq6o/3MG0t7z9lYztG1xfoGwPFG+HyT+NbFDGGNPODttYrKrvHotJ4JAxBOGccdQYY6JYzC6PtbukCl9A67uO5i8F8bhpoo0xJobEbCKoX4eg7o5gKWQPh4TUCEZljDHtL5QBZeeLSEaDx5kicl54wwq/g9YhCPhh+xfQb3KEozLGmPYXyh3BPapaXPdAVYuAe8IXUvuoG1XcKzMZdn0NNaXQf2qEozLGmPYXSiJoap9Qxx/MEJG1IrJBRG5v4vlHRGR58GudiBSFcty2sKukkq5pCW4MwdZP3cZ+tmCMMSb2hHJCXyIiDwOPBx9fj5uFtEXBkciPA2cAeUCuiMxV1dV1+6jqzQ32vxEYdwSxH5Wyaj/pSfHuwdZP3ECyjN7t9fbGGBM1QrkjuBGoAV4BXgaqcMngcCYBG1R1k6rWBF97bgv7Xw68FMJx20RFtY/keC+owrbFVhYyxsSsUOYaKgcOKeuEoDewvcHjPKDJ1lgR6Q8MBD5s5vlrgWsB+vVrm3UCKmr8pCZ6Ye86qCiE/ie1yXGNMaajCaXX0PvBhWnqHncWkXfbOI7LgNeaG7imqrNVdYKqTsjOzm6TN6yo9ZOcEOfKQmCJwBgTs0IpDXUN9hQCQFX3A91CeF0+By9p2Se4rSmX0Y5lIYDKGh8p8V7YuhjSekCX49rz7Y0xJmqEkggCInKgHhMs42gIr8sFBovIQBFJwJ3s5zbeSUSGAZ1p5+Uvy6v9pCR43B1B/xNtRTJjTMwKpdfQncDHIvIRIMA0gvX6lqiqT0RuAN4FvMCzqrpKRMnq17EAABP4SURBVO4HlqhqXVK4DHhZVUNJLm2mstZPLwqgJN8aio0xMS2UxuJ3ROQEYEpw0y9UdW8oB1fVecC8RtvubvT43tBCbVsVNT6GVAd7slr7gDEmhoU0MAzwA3uAJGCEiKCqi8IXVnj5A0pVbYCB5V9BUqabY8gYY2JUKAvT/AS4CdfYuxx3Z7AYt2xlh1RZ6zon9S1d7u4GPDE7954xxoTUWHwTMBHYqqqn4Ub/tttUEOFQUeMjmyIyK7batBLGmJgXSiKoUtUqABFJVNVvgKHhDSu8Kmv8TPR84x5YQ7ExJsaF0kaQFxxQ9gbwvojsB7aGN6zwKq/2M8GzDp83mbieYyIdjjHGRFQovYbOD357r4gsADJwC9l3WJW1PgbKTio7HUe6Nz7S4RhjTESF2msIAFX9KFyBtKeKGj99ZC+1nUZHOhRjjIm4mOwuU1Hto48UEOjUNhPYGWNMRxaTicBfuptkqYHOlgiMMSYmE4GneBsA3i4DIhuIMcZEgZhMBAmleQDEZw2IbCDGGBMFYjIRJJa5RJDUdUBkAzHGmCgQk4kgpTKfQu1EXHJ6pEMxxpiIi8lEkF6Zzw4JZW0dY4w59sVkIsio3slujyUCY4yBWEwEgQCZtbvZG9cz0pEYY0xUiL1EULaLeK1lX3yPSEdijDFRIfYSwX43X15Rgt0RGGMMxGIiKHKDyUqTe0U4EGOMiQ4xmAjcHUFFSu8IB2KMMdEhJhNBAZ1JSEyOdCTGGBMVYi8R7N9KPtmkJHgjHYkxxkSF2EsERdvYFsgmJfGIlmIwxphjVmwlAr8PLc5jW6ArKfF2R2CMMRBriaB0B6J+tms3kq00ZIwxQKwlguAYgjztSkqClYaMMQZiLREExxBs126kJtodgTHGQAwmAkXYqVkkWxuBMcYAMZcItlKT0oNa4qw0ZIwxQWFNBCIyQ0TWisgGEbm9mX0uEZHVIrJKRP4Wzngo2kZlqhtRnGKlIWOMASBsl8Ui4gUeB84A8oBcEZmrqqsb7DMYuAOYqqr7RcK8Wsz+rZRljgewAWXGGBMUzjuCScAGVd2kqjXAy8C5jfaZBTyuqvsBVHVP2KLx1UDpDkqS3GRzKfFWGjLGGAhvIugNbG/wOC+4raEhwBAR+UREPhORGU0dSESuFZElIrKkoKCgddGU5IEGKEpw6xDYOAJjjHEi3VgcBwwGTgUuB54WkczGO6nqbFWdoKoTsrOzW/dOwa6jdSuTWfdRY4xxwpkI8oG+DR73CW5rKA+Yq6q1qroZWIdLDG0vOJhsj7c7AElxlgiMMQbCmwhygcEiMlBEEoDLgLmN9nkDdzeAiHTFlYo2hSUaDUBGX/ZIF5LjvXg8Epa3McaYjiZsiUBVfcANwLvAGmCOqq4SkftFZGZwt3eBQhFZDSwAblXVwrAENOEauHkl5bViZSFjjGkgrF1nVHUeMK/RtrsbfK/AL4Nf7aKixm8NxcYY00CkG4vbXUWNz7qOGmNMAzGYCOyOwBhjGorJRGBtBMYYUy8mE0GylYaMMeaAmEsElTU+m2fIGGMaiLlEYKUhY4w5WEwmAisNGWNMvZhKBKrquo9aacgYYw6IqURQ7QsQUJt51BhjGoqpRFBZ4wcg1RKBMcYcEFOJoLzGB2DrFRtjTAMxdUasuyOw0pAx0am2tpa8vDyqqqoiHUqHlZSURJ8+fYiPjw/5NTGVCCrqSkPWfdSYqJSXl0d6ejoDBgxAxKaKP1KqSmFhIXl5eQwcODDk18Vkaci6jxoTnaqqqsjKyrIk0EoiQlZW1hHfUcVUIqgrDVn3UWOilyWBo9Oazy+mEkGFJQJjjDlETCWCA3cEiVYaMsaYOjGVCA50H423OwJjTNOKiop44oknjvh155xzDkVFRWGIKPxi6tK4wrqPGtNh3PfPVazeUdKmxxzRqxP3fG9ki/vUJYLrrrvuoO0+n4+4uOZPmfPmzWv2uWgXU3cElTV+vB4hMS6mfmxjzBG4/fbb2bhxI2PHjmXixIlMmzaNmTNnMmLECADOO+88xo8fz8iRI5k9e/aB1w0YMIC9e/eyZcsWhg8fzqxZsxg5ciRnnnkmlZWVzb7f008/zcSJE8nJyeHCCy+koqICgN27d3P++eeTk5NDTk4On376KQDPP/88Y8aMIScnh6uuuqptfmhV7VBf48eP19a6d+5KHXX3O61+vTEmvFavXh3pEHTz5s06cuRIVVVdsGCBpqSk6KZNmw48X1hYqKqqFRUVOnLkSN27d6+qqvbv318LCgp08+bN6vV69csvv1RV1YsvvlhfeOGFZt+v7vWqqnfeeaf+4Q9/UFXVSy65RB955BFVVfX5fFpUVKQrV67UwYMHa0FBwUGxNNbU5wgs0WbOqzFVGqq09YqNMUdo0qRJBw3O+sMf/sA//vEPALZv38769evJyso66DUDBw5k7NixAIwfP54tW7Y0e/yVK1dy1113UVRURFlZGWeddRYAH374Ic8//zwAXq+XjIwMnn/+eS6++GK6du0KQJcuXdrkZ4ypRFBR47euo8aYI5Kamnrg+4ULFzJ//nwWL15MSkoKp556apODtxITEw987/V6WywNXX311bzxxhvk5OTw3HPPsXDhwjaNPxQxVSx3iSCmcp8x5gilp6dTWlra5HPFxcV07tyZlJQUvvnmGz777LOjfr/S0lJ69uxJbW0tL7744oHt06dP58knnwTA7/dTXFzM6aefzquvvkphYSEA+/btO+r3h5hLBLYojTGmZVlZWUydOpVRo0Zx6623HvTcjBkz8Pl8DB8+nNtvv50pU6Yc9fv9+te/ZvLkyUydOpVhw4Yd2P7oo4+yYMECRo8ezfjx41m9ejUjR47kzjvv5JRTTiEnJ4df/vKXR/3+AOLaEDqOCRMm6JIlS1r12vMe/4T0pDhe+PHkNo7KGNMW1qxZw/DhwyMdRofX1OcoIktVdUJT+8fUHUFljZ9UKw0ZY8xBYuqsWFFrpSFjTGRcf/31fPLJJwdtu+mmm7jmmmsiFFG9sCYCEZkBPAp4gWdU9cFGz18N/BbID256TFWfCVc8FdXWfdQYExmPP/54pENoVtgSgYh4gceBM4A8IFdE5qrq6ka7vqKqN4Qrjoas+6gxxhwqnG0Ek4ANqrpJVWuAl4Fzw/h+LQoElMpa6z5qjDGNhTMR9Aa2N3icF9zW2IUiskJEXhORvuEKprLW1iIwxpimRLrX0D+BAao6Bngf+EtTO4nItSKyRESWFBQUtOqNbFEaY0woWjsNNcDvf//7A5PGdSThTAT5QMMr/D7UNwoDoKqFqlodfPgMML6pA6nqbFWdoKoTsrOzWxVM/TKVVhoyxjQvFhNBOM+KucBgERmISwCXAVc03EFEeqrqzuDDmcCacAVTURtclMbuCIzpGN6+HXZ93bbH7DEazn6wxV0aTkN9xhln0K1bN+bMmUN1dTXnn38+9913H+Xl5VxyySXk5eXh9/v51a9+xe7du9mxYwennXYaXbt2ZcGCBU0e/+c//zm5ublUVlZy0UUXcd999wGQm5vLTTfdRHl5OYmJiXzwwQekpKRw22238c477+DxeJg1axY33nhj234mhDERqKpPRG4A3sV1H31WVVeJyP246VDnAv8mIjMBH7APuDpc8ZRX26I0xpjDe/DBB1m5ciXLly/nvffe47XXXuOLL75AVZk5cyaLFi2ioKCAXr168dZbbwFuDqKMjAwefvhhFixYcGB20KY88MADdOnSBb/fz/Tp01mxYgXDhg3j0ksv5ZVXXmHixImUlJSQnJzM7Nmz2bJlC8uXLycuLq7N5hZqLKx1ElWdB8xrtO3uBt/fAdwRzhjqWGnImA7mMFfu7eG9997jvffeY9y4cQCUlZWxfv16pk2bxi233MJtt93Gd7/7XaZNmxbyMefMmcPs2bPx+Xzs3LmT1atXIyL07NmTiRMnAtCpUycA5s+fz89+9rMDK6O11bTTjcXMWbGixkpDxpgjo6rccccd/PSnPz3kuWXLljFv3jzuuusupk+fzt13393EEQ62efNmHnroIXJzc+ncuTNXX311k9NYt7dI9xpqN9ZryBgTiobTUJ911lk8++yzlJWVAZCfn8+ePXvYsWMHKSkpXHnlldx6660sW7bskNc2paSkhNTUVDIyMti9ezdvv/02AEOHDmXnzp3k5uYCbmpqn8/HGWecwR//+Ed8Pnch2yFLQ9GkwkpDxpgQNJyG+uyzz+aKK67gxBNPBCAtLY2//vWvbNiwgVtvvRWPx0N8fPyBdQOuvfZaZsyYQa9evZpsLM7JyWHcuHEMGzaMvn37MnXqVAASEhJ45ZVXuPHGG6msrCQ5OZn58+fzk5/8hHXr1jFmzBji4+OZNWsWN9zQ9hMxxMw01M/8axP/7601rLj3TDolxYchMmPM0bJpqNuGTUPdjH5dUpgxsgcp8VYaMsaYhmKmTnLmyB6cObJHpMMwxsSIyZMnU11dfdC2F154gdGjR0cooubFTCIwxpj29Pnnn0c6hJDFTGnIGNMxdLR2y2jTms/PEoExJmokJSVRWFhoyaCVVJXCwkKSkpKO6HVWGjLGRI0+ffqQl5dHa2cZNi6Z9unT54heY4nAGBM14uPjGThwYKTDiDlWGjLGmBhnicAYY2KcJQJjjIlxHW6KCREpALa28uVdgb1tGE5bitbYojUuiN7YojUuiN7YojUuOHZi66+qTS7x2OESwdEQkSXNzbURadEaW7TGBdEbW7TGBdEbW7TGBbERm5WGjDEmxlkiMMaYGBdriWB2pANoQbTGFq1xQfTGFq1xQfTGFq1xQQzEFlNtBMYYYw4Va3cExhhjGrFEYIwxMS5mEoGIzBCRtSKyQURuj3Asz4rIHhFZ2WBbFxF5X0TWB//tHIG4+orIAhFZLSKrROSmaIhNRJJE5AsR+SoY133B7QNF5PPg7/QVEUloz7gaxegVkS9F5M1oiU1EtojI1yKyXESWBLdF/O8sGEemiLwmIt+IyBoROTHSsYnI0OBnVfdVIiK/iHRcDeK7Ofj3v1JEXgr+v2iTv7OYSAQi4gUeB84GRgCXi8iICIb0HDCj0bbbgQ9UdTDwQfBxe/MBt6jqCGAKcH3wc4p0bNXA6aqaA4wFZojIFOC/gUdU9XhgP/Djdo6roZuANQ0eR0tsp6nq2AZ9zSP9u6zzKPCOqg4DcnCfXURjU9W1wc9qLDAeqAD+Eem4AESkN/BvwARVHQV4gctoq78zVT3mv4ATgXcbPL4DuCPCMQ0AVjZ4vBboGfy+J7A2Cj63/wPOiKbYgBRgGTAZN6IyrqnfcTvH1Ad3gjgdeBOQaIgN2AJ0bbQt4r9LIAPYTLCzSjTF1iCWM4FPoiUuoDewHeiCmzX6TeCstvo7i4k7Auo/xDp5wW3RpLuq7gx+vwvoHslgRGQAMA74nCiILVh6WQ7sAd4HNgJFquoL7hLJ3+nvgf8AAsHHWURHbAq8JyJLReTa4LaI/y6BgUAB8OdgOe0ZEUmNktjqXAa8FPw+4nGpaj7wELAN2AkUA0tpo7+zWEkEHYq69B6xfr0ikgb8HfiFqpY0fC5SsamqX90tex9gEjCsvWNoioh8F9ijqksjHUsTTlbVE3Al0etF5FsNn4zg31kccALwpKqOA8ppVG6J5P+BYJ19JvBq4+ciFVewXeJcXBLtBaRyaHm51WIlEeQDfRs87hPcFk12i0hPgOC/eyIRhIjE45LAi6r6ejTFBqCqRcAC3G1wpojULa4Uqd/pVGCmiGwBXsaVhx6NhtiCV5Go6h5crXsS0fG7zAPyVLVudffXcIkhGmIDlziXqeru4ONoiOvbwGZVLVDVWuB13N9em/ydxUoiyAUGB1vYE3C3fXMjHFNjc4EfBr//Ia4+365ERIA/AWtU9eFoiU1EskUkM/h9Mq7dYg0uIVwUqbgAVPUOVe2jqgNwf1cfqur3Ix2biKSKSHrd97ia90qi4O9MVXcB20VkaHDTdGB1NMQWdDn1ZSGIjri2AVNEJCX4/7TuM2ubv7NINcZEoLHlHGAdrrZ8Z4RjeQlX56vFXR39GFdX/gBYD8wHukQgrpNxt70rgOXBr3MiHRswBvgyGNdK4O7g9uOAL4ANuNv4xAj/Xk8F3oyG2ILv/1Xwa1Xd33ykf5cN4hsLLAn+Tt8AOkdDbLiSSyGQ0WBbxOMKxnEf8E3w/8ALQGJb/Z3ZFBPGGBPjYqU0ZIwxphmWCIwxJsZZIjDGmBhnicAYY2KcJQJjjIlxlgiMaUcicmrdDKXGRAtLBMYYE+MsERjTBBG5MrgGwnIR+WNw0rsyEXkkOCf8ByKSHdx3rIh8JiIrROQfdfPVi8jxIjI/uI7CMhEZFDx8WoO5+F8MjhQ1JmIsERjTiIgMBy4Fpqqb6M4PfB836nSJqo4EPgLuCb7keeA2VR0DfN1g+4vA4+rWUTgJN5oc3Kyuv8CtjXEcbs4YYyIm7vC7GBNzpuMWJskNXqwn4yYaCwCvBPf5K/C6iGQAmar6UXD7X4BXg/P89FbVfwCoahVA8HhfqGpe8PFy3NoUH4f/xzKmaZYIjDmUAH9R1TsO2ijyq0b7tXZ+luoG3/ux/4cmwqw0ZMyhPgAuEpFucGCd3/64/y91Mz1eAXysqsXAfhGZFtx+FfCRqpYCeSJyXvAYiSKS0q4/hTEhsisRYxpR1dUichdudS8PbpbY63ELqEwKPrcH144Abvrfp4In+k3ANcHtVwF/FJH7g8e4uB1/DGNCZrOPGhMiESlT1bRIx2FMW7PSkDHGxDi7IzDGmBhndwTGGBPjLBEYY0yMs0RgjDExzhKBMcbEOEsExhgT4/4/ZnLxkiLPRPAAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]}]}